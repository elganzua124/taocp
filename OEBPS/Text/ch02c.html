<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [["$","$"]],
        displayMath: [["$$","$$"]],
        processEscapes: true
      },
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
  <script src="MathJax-2.4-latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  <title></title>
  <link href="../Styles/caps.css" rel="stylesheet" type="text/css">
</head>

<body>
  <div class="heading">
    <h4 id="ch02lev2sec11">2.3.5. Lists and Garbage Collection</h4>

    <p>Near the beginning of <a href="../Text/ch02a.html#ch02lev1sec3">Section 2.3</a> we defined a List informally as “a finite sequence of zero or more atoms or Lists.”</p>
  </div>

  <p class="indent">Any forest is a List; for example,</p>

  <div class="equation"><a id="ch02eq-lev2sec11-1"></a><img src="../Images/ch02/408equ01.jpg"></div>

  <p>may be regarded as the List</p>

  <div class="equation"><a id="ch02eq-lev2sec11-2"></a><img src="../Images/ch02/408equ02.jpg"></div>

  <p>and the corresponding List diagram would be</p>

  <div class="equation"><a id="ch02eq-lev2sec11-3"></a><img src="../Images/ch02/408equ03.jpg"></div>

  <p class="indent">The reader should review at this point the introduction to Lists given earlier, in particular (<a href="../Text/ch02c.html#ch02eq-lev2sec11-3">3</a>), (<a href="../Text/ch02c.html#ch02eq-lev2sec11-4">4</a>), (<a href="../Text/ch02c.html#ch02eq-lev2sec11-5">5</a>), (<a href="../Text/ch02c.html#ch02eq-lev2sec11-6">6</a>), (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>) in the opening pages of <a href="../Text/ch02a.html#ch02lev1sec3">Section 2.3</a>. Recall that, in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-2">2</a>) above, the notation “<em>a:</em> (<em>b, c, d</em>)” means that (<em>b, c, d</em>) is a List of three atoms, which has been labeled with the attribute “<em>a</em>”. This convention is compatible <a id="page_409"></a>with our general policy that each node of a tree may contain information besides its structural connections. However, as was discussed for trees in <a href="../Text/ch02a.html#ch02lev2sec9">Section 2.3.3</a>, it is quite possible and sometimes desirable to insist that all Lists be unlabeled, so that all the information appears in the atoms.</p>

  <p class="indent">Although any forest may be regarded as a List, the converse is not true. The following List is perhaps more typical than (<a href="../Text/ch02c.html#ch02eq-lev2sec11-2">2</a>) and (<a href="../Text/ch02c.html#ch02eq-lev2sec11-3">3</a>) since it shows how the restrictions of tree structure might be violated:</p>

  <div class="equation"><a id="ch02eq-lev2sec11-4"></a><img src="../Images/ch02/409equ01.jpg"></div>

  <p>which may be diagrammed as</p>

  <div class="equation"><a id="ch02eq-lev2sec11-5"></a><img src="../Images/ch02/409equ02.jpg"></div>

  <p>[Compare with the example in <a href="../Text/ch02a.html#ch02lev1sec3">2.3</a>–(<a href="../Text/ch02a.html#ch02eq-lev1sec3-7">7</a>). The form of these diagrams need not be taken too seriously.]</p>

  <p class="indent">As we might expect, there are many ways to represent List structures within a computer memory. These methods are usually variations on the same basic theme by which we have used binary trees to represent general forests of trees: One field, say <code>RLINK</code>, is used to point to the next element of a List, and another field <code>DLINK</code> may be used to point to the first element of a sub-List. By a natural extension of the memory representation described in <a href="../Text/ch02a.html#ch02lev2sec8">Section 2.3.2</a>, we would represent the List (<a href="../Text/ch02c.html#ch02eq-lev2sec11-5">5</a>) as follows:</p>

  <div class="equation"><a id="ch02eq-lev2sec11-6"></a><img src="../Images/ch02/409equ03.jpg"></div>

  <p class="indent">Unfortunately, this simple idea is <em>not</em> quite adequate for the most common List processing applications. For example, suppose that we have the List <em>L</em> = (<em>A, a,</em> (<em>A, A</em>)), which contains three references to another List <em>A</em> = (<em>b, c, d</em>). One of the typical List processing operations is to remove the leftmost element of <em>A</em>, so that <em>A</em> becomes (<em>c, d</em>); but this requires <em>three</em> changes to the representation of <em>L</em>, if we are to use the technique shown in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-6">6</a>), since each pointer to <em>A</em> points <a id="page_410"></a>to the element <em>b</em> that is being deleted. A moment’s reflection will convince the reader that it is extremely undesirable to change the pointers in every reference to <em>A</em> just because the first element of <em>A</em> is being deleted. (In this example we could try to be tricky, assuming that there are no pointers to the element <em>c</em>, by copying the entire element <em>c</em> into the location formerly occupied by <em>b</em> and then deleting the old element <em>c</em>. But this trick fails to work when <em>A</em> loses its last element and becomes empty.)</p>

  <p class="indent">For this reason the representation scheme (<a href="../Text/ch02c.html#ch02eq-lev2sec11-6">6</a>) is generally replaced by another scheme that is similar, but uses a <em>List head</em> to begin each List, as was introduced in <a href="../Text/ch02.html#ch02lev2sec4">Section 2.2.4</a>. Each List contains an additional node called its List head, so that the configuration (<a href="../Text/ch02c.html#ch02eq-lev2sec11-6">6</a>) would, for example, be represented thus:</p>

  <div class="equation"><a id="ch02eq-lev2sec11-7"></a><img src="../Images/ch02/410equ01.jpg"></div>

  <p class="indent">The introduction of such header nodes is not really a waste of memory space in practice, since many uses for the apparently unused fields — the shaded areas in diagram (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>) — generally present themselves. For example, there is room for a reference count, or a pointer to the right end of the List, or an alphabetic name, or a “scratch” field that aids traversal algorithms, etc.</p>

  <p class="indent">In our original diagram (<a href="../Text/ch02c.html#ch02eq-lev2sec11-6">6</a>), the node containing <em>b</em> is an atom while the node containing <em>f</em> specifies an empty List. These two things are structurally identical, so the reader would be quite justified in asking why we bother to talk about “atoms” at all; with no loss of generality we could have defined Lists as merely “a finite sequence of zero or more Lists,” with our usual convention that each node of a List may contain data besides its structural information. This point of view is certainly defensible and it makes the concept of an “atom” seem very artificial. There is, however, a good reason for singling out atoms as we have done, when efficient use of computer memory is taken into consideration, since atoms are not subject to the same sort of general-purpose manipulation that is desired for Lists. The memory representation (<a href="../Text/ch02c.html#ch02eq-lev2sec11-6">6</a>) shows there is probably more room for information in an atomic node, <em>b</em>, than in a List node, <em>f</em>; and when List head nodes are also present as in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>), there is a dramatic difference between the storage requirements for the nodes <em>b</em> and <em>f</em> . Thus the concept of atoms is introduced primarily to aid in the effective use of computer memory. Typical <a id="page_411"></a>Lists contain many more atoms than our example would indicate; the example of (<a href="../Text/ch02c.html#ch02eq-lev2sec11-4">4</a>)–(<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>) is intended to show the complexities that are possible, not the simplicities that are usual.</p>

  <p class="indent">A List is in essence nothing more than a linear list whose elements may contain pointers to other Lists. The common operations we wish to perform on Lists are the usual ones desired for linear lists (creation, destruction, insertion, deletion, splitting, concatenation), plus further operations that are primarily of interest for tree structures (copying, traversal, input and output of nested information). For these purposes any of the three basic techniques for representing linked linear lists in memory — namely straight, circular, or double linkage — can be used, with varying degrees of efficiency depending on the algorithms being employed. For these three types of representation, diagram (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>) might appear in memory as follows:</p>

  <div class="equation"><a id="ch02eq-lev2sec11-8"></a><img src="../Images/ch02/411equ01.jpg"></div>

  <p>Here “<code>LLINK</code>” is used for a pointer to the left in a doubly linked representation. The <code>INFO</code> and <code>DLINK</code> fields are identical in all three forms.</p>

  <p class="indent">There is no need to repeat here the algorithms for List manipulation in any of these three forms, since we have already discussed the ideas many times. The following important points about Lists, which distinguish them from the simpler special cases treated earlier, should however be noted:</p>

  <p class="indent">1) It is implicit in the memory representation above that atomic nodes are distinguishable from nonatomic nodes; furthermore, when circular or doubly linked Lists are being used, it is desirable to distinguish header nodes from the other types, as an aid in traversing the Lists. Therefore each node generally contains a <code>TYPE</code> field that tells what kind of information the node represents. This <code>TYPE</code> field is often used also to distinguish between various types of atoms (for example, between alphabetic, integer, or floating point quantities, for use when manipulating or displaying the data).</p>

  <p class="indent">2) The format of nodes for general List manipulation with the <code>MIX</code> computer might be designed in one of the following two ways.</p>

  <p class="indenthangingNa"><a id="page_412"></a>a) Possible one-word format, assuming that all <code>INFO</code> appears in atoms:</p>

  <div class="equation"><a id="ch02eq-lev2sec11-9"></a><img src="../Images/ch02/412equ01.jpg"></div>

  <div class="imageL"><img src="../Images/ch02/p0412_01.jpg"></div>

  <p class="indenthangingNa">b) Possible two-word format:</p>

  <div class="equation"><a id="ch02eq-lev2sec11-10"></a><img src="../Images/ch02/412equ02.jpg"></div>

  <p class="uln-indent2"><code>S, T</code>:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-9">9</a>).</p>

  <div class="imageL"><img src="../Images/ch02/p0412_02.jpg"></div>

  <p class="indent">3) It is clear that Lists are very general structures; indeed, it seems fair to state that any structure whatsoever can be represented as a List when appropriate conventions are made. Because of this universality of Lists, a large number of programming systems have been designed to facilitate List manipulation, and there are usually several such systems available at any computer installation. Such systems are based on a general-purpose format for nodes such as (<a href="../Text/ch02c.html#ch02eq-lev2sec11-9">9</a>) or (<a href="../Text/ch02c.html#ch02eq-lev2sec11-10">10</a>) above, designed for flexibility in List operations. Actually, it is clear that this general-purpose format is usually not the best format suited to a <em>particular</em> application, and the processing time using the general-purpose routines is noticeably slower than a person would achieve by hand-tailoring the system to a particular problem. For example, it is easy to see that nearly all of the applications we have worked out so far in this chapter would be encumbered by a general-List representation as in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-9">9</a>) or (<a href="../Text/ch02c.html#ch02eq-lev2sec11-10">10</a>) instead of the node format that was given in each case. A List manipulation routine must often examine the <code>T</code>-field when it processes nodes, and that was not needed in any of our programs so far. This loss of efficiency is repaid in many instances by the comparative ease of programming and the reduction of debugging time when a general-purpose system is used.</p>

  <p class="indent">4) There is also an extremely significant difference between algorithms for List processing and the algorithms given previously in this chapter. Since a single <a id="page_413"></a>List may be contained in many other Lists, it is by no means clear exactly when a List should be returned to the pool of available storage. Our algorithms so far have always said “<code>AVAIL <span class="ent">⇐</span> X</code>”, whenever <code>NODE(X)</code> was no longer needed. But since general Lists can grow and die in a completely unpredictable manner, it is often quite difficult to tell just when a particular node is superfluous. Therefore the problem of maintaining the list of available space is considerably more difficult with Lists than it was in the simple cases considered previously. We will devote the rest of this section to a discussion of the storage reclamation problem.</p>

  <p class="indent">Let us imagine that we are designing a general-purpose List processing system that will be used by hundreds of other programmers. Two principal methods have been suggested for maintaining the available space list: the use of <em>reference counters</em>, and <em>garbage collection</em>. The reference-counter technique makes use of a new field in each node, which contains a count of how many arrows point to this node. Such a count is rather easy to maintain as a program runs, and whenever it drops to zero, the node in question becomes available. The garbage-collection technique, on the other hand, requires a new one-bit field in each node called the <em>mark bit</em>. The idea in this case is to write nearly all the algorithms so that they do not return any nodes to free storage, and to let the program run merrily along until all of the available storage is gone; then a “recycling” algorithm makes use of the mark bits to identify all nodes that are not currently accessible and to return them to available storage, after which the program can continue.</p>

  <p class="indent">Neither of these two methods is completely satisfactory. The principal drawback of the reference-counter method is that it does not always free all the nodes that are available. It works fine for overlapped Lists (Lists that contain common sub-Lists); but recursive Lists, like our examples <em>L</em> and <em>N</em> in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-4">4</a>), will <em>never</em> be returned to storage by the reference-counter technique. Their counts will be nonzero (since they refer to themselves) even when no other List accessible to the running program points to them. Furthermore, the referencecounter method uses a good chunk of space in each node (although this space is sometimes available anyway due to the computer word size).</p>

  <p class="indent">The difficulty with the garbage-collection technique, besides the annoying loss of a bit in each node, is that it runs very slowly when nearly all the memory space is in use; and in such cases the number of free storage cells found by the reclamation process is not worth the effort. Programs that exceed the capacity of storage (and many undebugged programs do!) often waste a good deal of time calling the garbage collector several almost fruitless times just before storage is finally exhausted. A partial solution to this problem is to let the programmer specify a number <em>k</em>, signifying that processing should not continue after a garbage collection run has found <em>k</em> or fewer free nodes.</p>

  <p class="indent">Another problem is the occasional difficulty of determining exactly what Lists are not garbage at a given stage. If the programmer has been using any nonstandard techniques or keeping any pointer values in unusual places, chances are good that the garbage collector will go awry. Some of the greatest mysteries in the history of debugging have been caused by the fact that garbage collection <a id="page_414"></a>suddenly took place at an unexpected time during the running of programs that had worked many times before. Garbage collection also requires that programmers keep valid information in all pointer fields at all times, although we often find it convenient to leave meaningless information in fields that the program doesn’t use — for example, the link in the rear node of a queue; see <a href="../Text/ch02.html#ch02lev2sec3">exercise 2.2.3</a>–<a href="../Text/ch02.html#ch02ex_2_3_4">6</a>.</p>

  <p class="indent">Although garbage collection requires one mark bit for each node, we could keep a separate table of all the mark bits packed together in another memory area, with a suitable correspondence between the location of a node and its mark bit. On some computers this idea can lead to a method of handling garbage collection that is more attractive than giving up a bit in each node.</p>

  <p class="indent">J. Weizenbaum has suggested an interesting modification of the reference-counter technique. Using doubly linked List structures, he puts a reference counter only in the header of each List. Thus, when pointer variables traverse a List, they are not included in the reference counts for the individual nodes. If we know the rules by which reference counts are maintained for entire Lists, we know (in theory) how to avoid referring to any List that has a reference count of zero. We also have complete freedom to explicitly override reference counts and to return particular Lists to available storage. These ideas require careful handling; they prove to be somewhat dangerous in the hands of inexperienced programmers, and they’ve tended to make program debugging more difficult due to the consequences of referring to nodes that have been erased. The nicest part of Weizenbaum’s approach is his treatment of Lists whose reference count has just gone to zero: Such a List is appended at the <em>end</em> of the current available list — this is easy to do with doubly linked Lists — and it is considered for available space only after all previously available cells are used up. Eventually, as the individual nodes of this List do become available, the reference counters of Lists <em>they</em> refer to are decreased by one. This delayed action of erasing Lists is quite efficient with respect to running time; but it tends to make incorrect programs run correctly for awhile! For further details see <em>CACM</em> <strong>6</strong> (1963), 524–544.</p>

  <p class="indent">Algorithms for garbage collection are quite interesting for several reasons. In the first place, such algorithms are useful in other situations when we want to mark all nodes that are directly or indirectly referred to by a given node. (For example, we might want to find all subroutines called directly or indirectly by a certain subroutine, as in exercise <a href="../Text/ch02.html#ch02lev2sec3">2.2.3</a>–<a href="../Text/ch02.html#ch02ex_2_3_26">26</a>.)</p>

  <p class="indent">Garbage collection generally proceeds in two phases. We assume that the mark bits of all nodes are initially zero (or we set them all to zero). Now the first phase marks all the nongarbage nodes, starting from those that are immediately accessible to the main program. The second phase makes a sequential pass over the entire memory pool area, putting all unmarked nodes onto the list of free space. The marking phase is the most interesting, so we will concentrate our attention on it. Certain variations on the second phase can, however, make it nontrivial; see <a href="../Text/ch02c.html#ch02ex_2_11_9">exercise 9</a>.</p>

  <p class="indent">When a garbage collection algorithm is running, only a very limited amount of storage is available to control the marking procedure. This intriguing problem <a id="page_415"></a>will become clear in the following discussion; it is a difficulty that is not appreciated by most people when they first hear about the idea of garbage collection, and for several years there was no good solution to it.</p>

  <p class="indent">The following marking algorithm is perhaps the most obvious.</p>

  <p><a id="ch02alg-lev2sec11-A"></a><strong>Algorithm A</strong> (<em>Marking</em>). Let the entire memory used for List storage be <code>NODE(1)</code>, <code>NODE(2)</code>, ..., <code>NODE(M)</code>, and suppose that these words either are atoms or contain two link fields <code>ALINK</code> and <code>BLINK</code>. Assume that all nodes are initially <em>unmarked</em>. The purpose of this algorithm is to <em>mark</em> all of the nodes that can be reached by a chain of <code>ALINK</code> and/or <code>BLINK</code> pointers in nonatomic nodes, starting from a set of “immediately accessible” nodes, that is, nodes pointed to by certain fixed locations in the main program; these fixed pointers are used as a source for all memory accesses.</p>

  <p class="indenthanging"><strong>A1.</strong> [Initialize.] Mark all nodes that are immediately accessible. Set <code>K</code> ← 1.</p>

  <p class="indenthanging"><strong>A2.</strong> [Does <code>NODE(K)</code> imply another?] Set <code>K1 ← K + 1. If NODE(K</code>) is an atom or unmarked, go to step A3. Otherwise, if <code>NODE(ALINK(K))</code> is unmarked: Mark it and, if it is not an atom, set <code>K1</code> ← min(<code>K1, ALINK(K))</code>. Similarly, if <code>NODE(BLINK(K))</code> is unmarked: Mark it and, if it is not an atom, set <code>K1</code> ← min(<code>K1, BLINK(K))</code>.</p>

  <p class="indenthanging"><strong>A3.</strong> [Done?] Set <code>K ← K1</code>. If <code>K ≤ M</code>, return to step A2; otherwise the algorithm terminates. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent"><em>Throughout this algorithm and the ones that follow in this section, we will assume for convenience that the nonexistent node “<code>NODE(Λ)</code>” is marked.</em> (For example, <code>ALINK(K)</code> or <code>BLINK(K)</code> may equal Λ in step A2.)</p>

  <p class="indent">A variant of <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithm A</a> sets <code>K1 ← M + 1</code> in step A1, removes the operation “<code>K1 ← K + 1</code>” from step A2, and instead changes step A3 to</p>

  <p class="indenthanging"><strong>A3</strong>′<strong>.</strong> [Done?] Set <code>K ← K + 1</code>. If <code>K ≤ M</code>, return to step A2. Otherwise if <code>K1 ≤ M</code>, set <code>K ← K1</code> and <code>K1 ← M + 1</code> and return to step A2. Otherwise the algorithm terminates. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent">It is very difficult to give a precise analysis of <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithm A</a>, or to determine whether it is better or worse than the variant just described, since no meaningful way to describe the probability distribution of the input presents itself. We can say that it takes up time proportional to <em>n</em><code>M</code> in the worst case, where <em>n</em> is the number of cells it marks; and, in general, we can be sure that it is very slow when <em>n</em> is large. <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithm A</a> is too slow to make garbage collection a usable technique.</p>

  <p class="indent">Another fairly evident marking algorithm is to follow all paths and to record branch points on a stack as we go:</p>

  <p><a id="ch02alg-lev2sec11-B"></a><strong>Algorithm B</strong> (<em>Marking</em>). This algorithm achieves the same effect as <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithm A</a>, using <code>STACK[1]</code>, <code>STACK[2]</code>, ... as auxiliary storage to keep track of all paths that have not yet been pursued to completion.</p>

  <p class="indenthanging"><strong>B1.</strong> [Initialize.] Let <code>T</code> be the number of immediately accessible nodes; mark them and place pointers to them in <code>STACK[1]</code>, ..., <code>STACK[T]</code>.</p>

  <p class="indenthanging"><a id="page_416"></a><strong>B2.</strong> [Stack empty?] If <code>T</code> = 0, the algorithm terminates.</p>

  <p class="indenthanging"><strong>B3.</strong> [Remove top entry.] Set <code>K ← STACK[T], T ← T − 1.</code></p>

  <p class="indenthanging"><strong>B4.</strong> [Examine links.] If <code>NODE(K)</code> is an atom, return to step B2. Otherwise, if <code>NODE(ALINK(K))</code> is unmarked, mark it and set <code>T ← T + 1, STACK[T] ← ALINK(K)</code>; if <code>NODE(BLINK(K))</code> is unmarked, mark it and set <code>T ← T + 1, STACK[T] ← BLINK(K)</code>. Return to B2. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent"><a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a> clearly has an execution time essentially proportional to the number of cells it marks, and this is as good as we could possibly expect; but it is not really usable for garbage collection because there is no place to keep the stack! It does not seem unreasonable to assume that the stack in <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a> might grow up to, say, five percent of the size of memory; but when garbage collection is called, and all available space has been used up, there is only a fixed (rather small) number of cells to use for such a stack. Most of the early garbage collection procedures were essentially based on this algorithm. If the special stack space was used up, the entire program had to be terminated.</p>

  <p class="indent">A somewhat better alternative is possible, using a fixed stack size, by combining <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">B</a>:</p>

  <p><a id="ch02alg-lev2sec11-C"></a><strong>Algorithm C</strong> (<em>Marking</em>). This algorithm achieves the same effect as <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">B</a>, using an auxiliary table of <code>H</code> cells, <code>STACK[0], STACK[1], ..., STACK[H − 1]</code>.</p>

  <p class="indent">In this algorithm, the action “insert <code>X</code> on the stack” means the following: “Set <code>T ← (T + 1)</code> mod <code>H</code>, and <code>STACK[T] ← X</code>. If <code>T = B</code>, set <code>B ← (B + 1)</code> mod <code>H</code> and <code>K1</code> ← min(<code>K1<em>,</em> STACK[B]</code>).” (Note that <code>T</code> points to the current top of the stack, and <code>B</code> points one place below the current bottom; <code>STACK</code> essentially operates as an input-restricted deque.)</p>

  <p class="indenthanging"><strong>C1.</strong> [Initialize.] Set <code>T ← H − 1, B ← H − 1, K1 ← M + 1</code>. Mark all the immediately accessible nodes, and successively insert their locations onto the stack (as just described above).</p>

  <p class="indenthanging"><strong>C2.</strong> [Stack empty?] If <code>T = B</code>, go to C5.</p>

  <p class="indenthanging"><strong>C3.</strong> [Remove top entry.] Set <code>K ← STACK[T], T ← (T − 1</code>) mod H.</p>

  <p class="indenthanging"><strong>C4.</strong> [Examine links.] If <code>NODE(K)</code> is an atom, return to step C2. Otherwise, if <code>NODE(ALINK(K))</code> is unmarked, mark it and insert <code>ALINK(K)</code> on the stack. Similarly, if <code>NODE(BLINK(K))</code> is unmarked, mark it and insert <code>BLINK(K)</code> on the stack. Return to C2.</p>

  <p class="indenthanging"><strong>C5.</strong> [Sweep.] If <code>K1</code> &gt; <code>M</code>, the algorithm terminates. (The variable <code>K1</code> represents the smallest location where there is a possibility of a new lead to a node that should be marked.) Otherwise, if <code>NODE(K1)</code> is an atom or unmarked, increase <code>K1</code> by 1 and repeat this step. If <code>NODE(K1)</code> is marked, set <code>K ← K1</code>, increase <code>K1</code> by 1, and go to C4. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent">This algorithm and <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a> can be improved if <code>X</code> is never put on the stack when <code>NODE(X)</code> is an atom; moreover, steps B4 and C4 need not put items on the stack when they know that the items will immediately be removed. Such <a id="page_417"></a>modifications are straightforward and they have been left out to avoid making the algorithms unnecessarily complicated.</p>

  <p class="indent"><a href="../Text/ch02c.html#ch02alg-lev2sec11-C">Algorithm C</a> is essentially equivalent to <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithm A</a> when <code>H</code> = 1, and to <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a> when <code>H</code> = <code>M</code>; it gradually becomes more efficient as <code>H</code> becomes larger. Unfortunately, <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">Algorithm C</a> defies a precise analysis for the same reason as <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithm A</a>, and we have no good idea how large <code>H</code> should be to make this method fast enough. It is plausible but uncomfortable to say that a value like <code>H</code> = 50 is sufficient to make <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">Algorithm C</a> usable for garbage collection in most applications.</p>

  <p class="indent"><a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a> use a stack kept in sequential memory locations; but we have seen earlier in this chapter that linked memory techniques are well suited to maintaining stacks that are not consecutive in memory. This suggests the idea that we might keep the stack of <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a> somehow scattered <em>through the same memory area in which we are collecting garbage</em>. This could be done easily if we were to give the garbage collection routine a little more room in which to breathe. Suppose, for example, we assume that all Lists are represented as in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-9">9</a>), except that the <code>REF</code> fields of List head nodes are used for garbage collection purposes instead of as reference counts. We can then redesign <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a> so that the stack is maintained in the <code>REF</code> fields of the header nodes:</p>

  <p><a id="ch02alg-lev2sec11-D"></a><strong>Algorithm D</strong> (<em>Marking</em>). This algorithm achieves the same effect as <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a>, <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">B</a>, and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a>, but it assumes that the nodes have <code>S, T, REF</code>, and <code>RLINK</code> fields as described above, instead of <code>ALINK</code>s and <code>BLINK</code>s. The <code>S</code> field is used as the mark bit, so that <code>S(P)</code> = 1 means that <code>NODE(P)</code> is marked.</p>

  <p class="indenthanging"><strong>D1.</strong> [Initialize.] Set <code>TOP</code> ← <em>Λ</em>. Then for each pointer <code>P</code> to the head of an immediately accessible List (see step A1 of <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithm A</a>), if <code>S(P)</code> = 0, set <code>S(P) ← 1, REF(P) ← TOP, TOP ← P.</code></p>

  <p class="indenthanging"><strong>D2.</strong> [Stack empty?] If <code>TOP</code> = <em>Λ</em>, the algorithm terminates.</p>

  <p class="indenthanging"><strong>D3.</strong> [Remove top entry.] Set <code>P ← TOP, TOP ← REF(P).</code></p>

  <p class="indenthanging"><strong>D4.</strong> [Move through List.] Set <code>P ← RLINK(P)</code>; then if <code>P</code> = <em>Λ</em>, or if <code>T(P)</code> = 0, go to D2. Otherwise set <code>S(P)</code> ← 1. If <code>T(P)</code> &gt; 1, set <code>S(REF(P)) ← 1</code> (thereby marking the atomic information). Otherwise <code>(T(P) = 1)</code>, set <code>Q ← REF(P); if Q ≠ <em>Λ</em></code> and <code>S(Q) = 0</code>, set <code>S(Q) ← 1, REF(Q) ← TOP, TOP ← Q</code>. Repeat step D4. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent"><a href="../Text/ch02c.html#ch02alg-lev2sec11-D">Algorithm D</a> may be compared to <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a>, which is quite similar, and its running time is essentially proportional to the number of nodes marked. However, <a href="../Text/ch02c.html#ch02alg-lev2sec11-D">Algorithm D</a> is <em>not</em> recommended without qualification, because its seemingly rather mild restrictions are often too stringent for a general Listprocessing system. This algorithm essentially requires that all List structures be well-formed, as in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>), whenever garbage collection is called into action. But algorithms for List manipulations <em>momentarily</em> leave the List structures malformed, and a garbage collector such as <a href="../Text/ch02c.html#ch02alg-lev2sec11-D">Algorithm D</a> must not be used during those momentary periods. Moreover, care must be taken in step D1 when the program contains pointers to the middle of a List.</p>

  <div class="image">
    <a id="page_418"></a><a id="ch02fig38"></a><img src="../Images/ch02/02fig38.jpg">

    <p class="fig-caption"><strong>Fig. 38.</strong> <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> for marking with no auxiliary stack space.</p>
  </div>

  <p class="indent">These considerations bring us to <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a>, which is an elegant marking method discovered independently by Peter Deutsch and by Herbert Schorr and W. M. Waite in 1965. The assumptions used in this algorithm are just a little different from those of <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a> through <a href="../Text/ch02c.html#ch02alg-lev2sec11-D">D</a>.</p>

  <p><a id="ch02alg-lev2sec11-E"></a><strong>Algorithm E</strong> (<em>Marking</em>). Assume that a collection of nodes is given having the following fields:</p>

  <p class="uln-indent"><code>MARK</code> (a one-bit field),</p>

  <p class="uln-indent"><code>ATOM</code> (another one-bit field),</p>

  <p class="uln-indent"><code>ALINK</code> (a pointer field),</p>

  <p class="uln-indent"><code>BLINK</code> (a pointer field).</p>

  <p>When <code>ATOM</code> = 0, the <code>ALINK</code> and <code>BLINK</code> fields may contain <em>Λ</em> or a pointer to another node of the same format; when <code>ATOM</code>= <code>1</code>, the contents of the <code>ALINK</code> and <code>BLINK</code> fields are irrelevant to this algorithm.</p>

  <p class="indent">Given a nonnull pointer <code>PO,</code> this algorithm sets the <code>MARK</code> field equal to 1 in <code>NODE(PO)</code> and in every other node that can be reached from <code>NODE(PO)</code> by a chain of <code>ALINK</code> and <code>BLINK</code> pointers in nodes with <code>ATOM = MARK =</code> 0. The algorithm uses three pointer variables, <code>T, Q,</code> and <code>P.</code> It modifies the links and control bits in such a way that all <code>ATOM, ALINK,</code> and <code>BLINK</code> fields are restored to their original settings after completion, although they may be changed temporarily.</p>

  <p class="indenthanging"><strong>E1.</strong> [Initialize.] Set <code>T</code> ← <em>Λ</em>, <code>P</code> ← <code>PO.</code> (Throughout the remainder of this algorithm, the variable <code>T</code> has a dual significance: When <code>T</code> ≠ <em>Λ</em>, it points to the top of what is essentially a stack as in <a href="../Text/ch02c.html#ch02alg-lev2sec11-D">Algorithm D</a>; and the node that <code>T</code> points to once contained a link equal to <code>P</code> in place of the “artificial” stack link that currently occupies <code>NODE(T)</code>.)</p>

  <p class="indenthanging"><strong>E2.</strong> [Mark.] Set <code>MARK(P)</code> ← 1.</p>

  <p class="indenthanging"><strong>E3.</strong> [Atom?] If <code>ATOM(P)</code> = 1, go to E6.</p>

  <p class="indenthanging"><strong>E4.</strong> [Down <code>ALINK.</code>] Set <code>Q</code> ← <code>ALINK(P)</code>. If <code>Q</code> ≠ <em>Λ</em> and <code>MARK(Q)</code> = 0, set <code>ATOM(P)</code> ← 1, <code>ALINK(P)</code> ← <code>T, T</code> ← <code>P, P</code> ← <code>Q</code>, and go to E2. (Here the <code>ATOM</code> field and <code>ALINK</code> fields are temporarily being altered, so that the List structure in certain marked nodes has been rather drastically changed. But these changes will be restored in step E6.)</p>

  <p class="indenthanging"><strong>E5.</strong> [Down <code>BLINK</code>.] Set <code>Q</code> ← <code>BLINK(P)</code>. If <code>Q</code> ≠ <em>Λ</em> and <code>MARK(Q)</code> = 0, set <code>BLINK(P)</code> ← <code>T</code>, <code>T</code> ← <code>P, P</code> ← <code>Q</code>, and go to E2.</p>

  <div class="image">
    <a id="page_419"></a><a id="ch02fig39"></a><img src="../Images/ch02/02fig39.jpg">

    <p class="fig-caption"><strong>Fig. 39.</strong> A structure marked by <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a>. (The table shows only changes that have occurred since the previous step.)</p>
  </div>

  <p class="indenthanging"><strong>E6.</strong> [Up.] (This step undoes the link switching made in step E4 or E5; the setting of <code>ATOM(T)</code> tells whether <code>ALINK(T)</code> or <code>BLINK(T)</code> is to be restored.) If <code>T</code> = <em>Λ</em>, the algorithm terminates. Otherwise set <code>Q ← T.</code> If <code>ATOM(Q)</code> = 1, set <code>ATOM(Q)</code> ← 0, <code>T ← ALINK(Q), ALINK(Q)</code> ← <code>P, P ← Q,</code> and return to E5. If <code>ATOM(Q)</code> = 0, set <code>T ← BLINK(Q), BLINK(Q) ← P, P ← Q,</code> and repeat E6. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent">An example of this algorithm in action appears in <a href="../Text/ch02c.html#ch02fig39">Fig. 39</a>, which shows the successive steps encountered for a simple List structure. The reader will find it worthwhile to study <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> very carefully; notice how the linking structure is artificially changed in steps E4 and E5, in order to maintain a stack analogous to the stack in <a href="../Text/ch02c.html#ch02alg-lev2sec11-D">Algorithm D</a>. When we return to a previous state, the <code>ATOM</code> field is used to tell whether <code>ALINK</code> or <code>BLINK</code> contains the artificial address. The “nesting” shown at the bottom of <a href="../Text/ch02c.html#ch02fig39">Fig. 39</a> illustrates how each nonatomic node is visited three times during <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a>: The same configuration <code>(T,P)</code> occurs at the beginning of steps E2, E5, and E6.</p>

  <p class="indent"><a id="page_420"></a>A proof that <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> is valid can be formulated by induction on the number of nodes that are to be marked. We prove at the same time that <code>P</code> returns to its initial value <code>P0</code> at the conclusion of the algorithm; for details, see <a href="../Text/ch02c.html#ch02ex_2_11_3">exercise 3</a>. <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> will run faster if step E3 is deleted and if special tests for “<code>ATOM(Q)</code> = 1” and appropriate actions are made in steps E4 and E5, as well as a test “<code>ATOM(P0)</code> = 1” in step E1. We have stated the algorithm in its present form for simplicity; the modifications just stated appear in the answer to <a href="../Text/ch02c.html#ch02ex_2_11_4">exercise 4</a>.</p>

  <p class="indent">The idea used in <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> can be applied to problems other than garbage collection; in fact, its use for tree traversal has already been mentioned in exercise <a href="../Text/ch02a.html#ch02lev2sec7">2.3.1</a>–<a href="../Text/ch02a.html#ch02ex_2_7_21">21</a>. The reader may also find it useful to compare <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> with the simpler problem solved in exercise <a href="../Text/ch02.html#ch02lev2sec3">2.2.3</a>–<a href="../Text/ch02.html#ch02ex_2_3_4">7</a>.</p>

  <p class="indent">Of all the marking algorithms we have discussed, only <a href="../Text/ch02c.html#ch02alg-lev2sec11-D">Algorithm D</a> is directly applicable to Lists represented as in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-9">9</a>). The other algorithms all test whether or not a given node <code>P</code> is an atom, and the conventions of (<a href="../Text/ch02c.html#ch02eq-lev2sec11-9">9</a>) are incompatible with such tests because they allow atomic information to fill an entire word except for the mark bit. However, each of the other algorithms can be modified so that they will work when atomic data is distinguished from pointer data in the word that links to it instead of by looking at the word itself. In <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a> or <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a> we can simply avoid marking atomic words until all nonatomic words have been properly marked; then one further pass over all the data suffices to mark all the atomic words. <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a> is even easier to modify, since we need merely keep atomic words off the stack. The adaptation of <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> is almost as simple, although if both <code>ALINK</code> and <code>BLINK</code> are allowed to point to atomic data it will be necessary to introduce another 1-bit field in nonatomic nodes. This is generally not hard to do. (For example, when there are two words per node, the least significant bit of each link field may be used to store temporary information.)</p>

  <p class="indent">Although <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> requires a time proportional to the number of nodes it marks, this constant of proportionality is not as small as in <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a>; the fastest garbage collection method known combines <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">E</a>, as discussed in <a href="../Text/ch02c.html#ch02ex_2_11_5">exercise 5</a>.</p>

  <p class="indent">Let us now try to make some quantitative estimates of the efficiency of garbage collection, as opposed to the philosophy of “<code>AVAIL <span class="ent">⇐</span> X</code>” that was used in most of the previous examples in this chapter. In each of the previous cases we could have omitted all specific mention of returning nodes to free space and we could have substituted a garbage collector instead. (In a special-purpose application, as opposed to a set of general-purpose List manipulation subroutines, the programming and debugging of a garbage collector is more difficult than the methods we have used, and, of course, garbage collection requires an extra bit reserved in each node; but we are interested here in the relative speed of the programs once they have been written and debugged.)</p>

  <p class="indent">The best garbage collection routines known have an execution time essentially of the form <em>c</em><sub>1</sub><code>N</code> + <em>c</em><sub>2</sub><code>M</code>, where <em>c</em><sub>1</sub> and <em>c</em><sub>2</sub> are constants, <code>N</code> is the number of nodes marked, and <code>M</code> is the total number of nodes in the memory. Thus <code>M − N</code> is <a id="page_421"></a>the number of free nodes found, and the amount of time required to return these nodes to free storage is (<em>c</em><sub>1</sub><code>N</code> + <em>c</em><sub>2</sub><code>M</code>)<em>/</em>(<code>M − N</code>) per node. Let <code>N</code> = <em>ρ</em><code>M</code>; this figure becomes (<em>c</em><sub>1</sub><em>ρ</em>+<em>c</em><sub>2</sub>) <em>/</em>(1−<em>ρ</em>). So if <span class="middle"><img src="../Images/ch02/421fig01.jpg"></span>, that is, if the memory is three-fourths full, we spend 3<em>c</em><sub>1</sub> + 4<em>c</em><sub>2</sub> units of time per free node returned to storage; when <span class="middle"><img src="../Images/ch02/421fig02.jpg"></span>, the corresponding cost is only <span class="middle"><img src="../Images/ch02/421fig03.jpg"></span> . If we do not use the garbage collection technique, the amount of time per node returned is essentially a constant, <em>c</em><sub>3</sub>, and it is doubtful that <em>c</em><sub>3</sub>/<em>c</em><sub>1</sub> will be very large. Hence we can see to what extent garbage collection is inefficient when the memory becomes full, and how it is correspondingly efficient when the demand on memory is light.</p>

  <p class="indent">Many programs have the property that the ratio <em>ρ</em> = <code>N<em>/</em>M</code> of good nodes to total memory is quite small. When the pool of memory becomes full in such cases, it might be best to move all the active List data to another memory pool of equal size, using a copying technique (see <a href="../Text/ch02c.html#ch02ex_2_11_10">exercise 10</a>) but without bothering to preserve the contents of the nodes being copied. Then when the second memory pool fills up, we can move the data back to the first one again. With this method more data can be kept in high-speed memory at once, because link fields tend to point to nearby nodes. Moreover, there’s no need for a marking phase, and storage allocation is simply sequential.</p>

  <p class="indent">It is possible to combine garbage collection with some of the other methods of returning cells to free storage; these ideas are not mutually exclusive, and some systems employ both the reference counter and the garbage collection schemes, besides allowing the programmer to erase nodes explicitly. The idea is to employ garbage collection only as a “last resort” whenever all other methods of returning cells have failed. An elaborate system, which implements this idea and also includes a mechanism for postponing operations on reference counts in order to achieve further efficiency, has been described by L. P. Deutsch and D. G. Bobrow in <em>CACM</em> <strong>19</strong> (1976), 522–526.</p>

  <p class="indent">A sequential representation of Lists, which saves many of the link fields at the expense of more complicated storage management, is also possible. See N. E. Wiseman and J. O. Hiles, <em>Comp. J.</em> <strong>10</strong> (1968), 338–343; W. J. Hansen, <em>CACM</em> <strong>12</strong> (1969), 499–507; and C. J. Cheney, <em>CACM</em> <strong>13</strong> (1970), 677–678.</p>

  <p class="indent">Daniel P. Friedman and David S. Wise have observed that the reference counter method can be employed satisfactorily in many cases even when Lists point to themselves, if certain link fields are not included in the counts [<em>Inf. Proc. Letters</em> <strong>8</strong> (1979), 41–45].</p>

  <p class="indent">A great many variants and refinements of garbage collection algorithms have been proposed. Jacques Cohen, in <em>Computing Surveys</em> <strong>13</strong> (1981), 341–367, presents a detailed review of the literature prior to 1981, with important comments about the extra cost of memory accesses when pages of data are shuttled between slow memory and fast memory.</p>

  <p class="indent">Garbage collection as we have described it is unsuitable for “real time” applications, where each basic List operation must be quick; even if the garbage collector goes into action infrequently, it requires large chunks of computer time on those occasions. <a href="../Text/ch02c.html#ch02ex_2_11_12">Exercise 12</a> discusses some approaches by which real-time garbage collection is possible.</p>

  <p class="blockquote"><a id="page_422"></a><span class="roman_italic">It is a very sad thing nowadays<br>
  that there is so little useless information.</span></p>

  <p class="attribution">— OSCAR WILDE (1894)</p>

  <p class="ex-title">Exercises</p>

  <p class="exercises2"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_2_11_1a" id="ch02ex_2_11_1">1</a>.</strong> [<em>M21</em>] In <a href="../Text/ch02b.html#ch02lev2sec10">Section 2.3.4</a> we saw that trees are special cases of the “classical” mathematical concept of a directed graph. Can Lists be described in graph-theoretic terminology?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_2_11_2a" id="ch02ex_2_11_2">2</a>.</strong> [<em>20</em>] In <a href="../Text/ch02a.html#ch02lev2sec7">Section 2.3.1</a> we saw that tree traversal can be facilitated using a threaded representation inside the computer. Can List structures be threaded in an analogous way?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_2_11_3a" id="ch02ex_2_11_3">3</a>.</strong> [<em>M26</em>] Prove the validity of <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a>. [<em>Hint:</em> See the proof of <a href="../Text/ch02a.html#ch02alg-lev2sec7-T">Algorithm 2.3.1T</a>.]</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_2_11_4a" id="ch02ex_2_11_4">4</a>.</strong> [<em>28</em>] Write a <code>MIX</code> program for <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a>, assuming that nodes are represented as one <code>MIX</code> word, with <code>MARK</code> the (0 : 0) field [“+” = 0, “−” = 1], <code>ATOM</code> the (1 : 1) field, <code>ALINK</code> the (2 : 3) field, <code>BLINK</code> the (4 : 5) field, and <em>Λ</em> = 0. Also determine the execution time of your program in terms of relevant parameters. (In the <code>MIX</code> computer the problem of determining whether a memory location contains −0 or +0 is not quite trivial, and this can be a factor in your program.)</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_2_11_5a" id="ch02ex_2_11_5">5</a>.</strong> [<em>25</em>] (Schorr and Waite.) Give a marking algorithm that combines <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">E</a> as follows: The assumptions of <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> with regard to fields within the nodes, etc., are retained; but an auxiliary stack <code>STACK[1], STACK[2]</code>, ..., <code>STACK[N]</code> is used as in <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithm B</a>, and the mechanism of <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> is employed only when the stack is full.</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_2_11_6a" id="ch02ex_2_11_6">6</a>.</strong> [<em>00</em>] The quantitative discussion at the end of this section says that the cost of garbage collection is approximately <em>c</em><sub>1</sub><code>N</code> + <em>c</em><sub>2</sub><code>M</code> units of time; where does the “<em>c</em><sub>2</sub><code>M</code>” term come from?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_2_11_7a" id="ch02ex_2_11_7">7</a>.</strong> [<em>24</em>] (R. W. Floyd.) Design a marking algorithm that is similar to <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a> in using no auxiliary stack, except that (i) it has a more difficult task to do, because each node contains only <code>MARK, ALINK</code>, and <code>BLINK</code> fields — there is no <code>ATOM</code> field to provide additional control; yet (ii) it has a simpler task to do, because it marks only a binary tree instead of a general List. Here <code>ALINK</code> and <code>BLINK</code> are the usual <code>LLINK</code> and <code>RLINK</code> in a binary tree.</p>

  <p class="exercises2"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_2_11_8a" id="ch02ex_2_11_8">8</a>.</strong> [<em>27</em>] (L. P. Deutsch.) Design a marking algorithm similar to <a href="../Text/ch02c.html#ch02alg-lev2sec11-D">Algorithms D</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">E</a> in that it uses no auxiliary memory for a stack, but modify the method so that it works with nodes of variable size and with a variable number of pointers having the following format: The first word of a node has two fields <code>MARK</code> and <code>SIZE</code>; the <code>MARK</code> field is to be treated as in <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a>, and the <code>SIZE</code> field contains a number <em>n</em> ≥ 0. This means that there are <em>n</em> consecutive words after the first word, each containing two fields <code>MARK</code> (which is zero and should remain so) and <code>LINK</code> (which is <em>Λ</em> or points to the first word of another node). For example, a node with three pointers would comprise four consecutive words:</p>

  <div class="image"><img src="../Images/ch02/e422_001.jpg"></div>

  <p class="exercisesp">Your algorithm should mark all nodes reachable from a given node <code>P0</code>.</p>

  <p class="exercises2"><a id="page_423"></a><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_2_11_9a" id="ch02ex_2_11_9">9</a>.</strong> [<em>28</em>] (D. Edwards.) Design an algorithm for the second phase of garbage collection that “compacts storage” in the following sense: Let <code>NODE(1)</code>, ..., <code>NODE(M)</code> be one-word nodes with fields <code>MARK, ATOM, ALINK</code>, and <code>BLINK</code>, as described in <a href="../Text/ch02c.html#ch02alg-lev2sec11-E">Algorithm E</a>. Assume that <code>MARK</code> = 1 in all nodes that are not garbage. The desired algorithm should relocate the marked nodes, if necessary, so that they all appear in consecutive locations <code>NODE(1)</code>, ..., <code>NODE(K)</code>, and at the same time the <code>ALINK</code> and <code>BLINK</code> fields of nonatomic nodes should be altered if necessary so that the List structure is preserved.</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_2_11_10a" id="ch02ex_2_11_10">10</a>.</strong> [<em>28</em>] Design an algorithm that copies a List structure, assuming that an internal representation like that in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>) is being used. (Thus, if your procedure is asked to copy the List whose head is the node at the upper left corner of (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>), a new set of Lists having 14 nodes, and with structure and information identical to that shown in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-7">7</a>), should be created.)</p>

  <p class="indent">Assume that the List structure is stored in memory using <code>S, T, REF</code>, and <code>RLINK</code> fields as in (<a href="../Text/ch02c.html#ch02eq-lev2sec11-9">9</a>), and that <code>NODE(P0)</code> is the head of the List to be copied. Assume further that the <code>REF</code> field in each List head node is <em>Λ</em>; to avoid the need for additional memory space, your copying procedure should make use of the <code>REF</code> fields (and reset them to <em>Λ</em> again afterwards).</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_2_11_11a" id="ch02ex_2_11_11">11</a>.</strong> [<em>M30</em>] Any List structure can be “fully expanded” into a tree structure by repeating all overlapping elements until none are left; when the List is recursive, this gives an infinite tree. For example, the List (<a href="../Text/ch02c.html#ch02eq-lev2sec11-5">5</a>) would expand into an infinite tree whose first four levels are</p>

  <div class="image"><img src="../Images/ch02/423fig01.jpg"></div>

  <p class="indent">Design an algorithm to test the <em>equivalence</em> of two List structures, in the sense that they have the same diagram when fully expanded. For example, Lists <em>A</em> and <em>B</em> are equivalent in this sense, if</p>

  <p class="uln-indent3a"><em>A = (a: C, b, a: (b: D))</em></p>

  <p class="uln-indent3a"><em>B = (a: (b: D), b, a: E)</em></p>

  <p class="uln-indent3a"><em>C = (b: (a: C))</em></p>

  <p class="uln-indent3a"><em>D = (a: (b: D))</em></p>

  <p class="uln-indent3a"><em>E = (b: (a: C)).</em></p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_2_11_12a" id="ch02ex_2_11_12">12</a>.</strong> [<em>30</em>] (M. Minsky.) Show that it is possible to use a garbage collection method reliably in a “real time” application, for example when a computer is controlling some physical device, even when stringent upper bounds are placed on the maximum execution time required for each List operation performed. [<em>Hint:</em> Garbage collection can be arranged to work in parallel with the List operations, if appropriate care is taken.]</p>

  <div class="heading">
    <h3 id="ch02lev1sec4"><a id="page_424"></a>2.4. Multilinked Structures</h3>

    <p>Now that we have examined linear lists and tree structures in detail, the principles of representing structural information within a computer should be evident. In this section we will look at another application of these techniques, this time for the typical case in which the structural information is slightly more complicated: In higher-level applications, several types of structure are usually present simultaneously.</p>
  </div>

  <p class="indent">A “multilinked structure” involves nodes with several link fields in each node, not just one or two as in most of our previous examples. We have already seen some examples of multiple linkage, such as the simulated elevator system in <a href="../Text/ch02.html#ch02lev2sec5">Section 2.2.5</a> and the multivariate polynomials in <a href="../Text/ch02a.html#ch02lev2sec9">Section 2.3.3</a>.</p>

  <p class="indent">We shall see that the presence of many different kinds of links per node does <em>not</em> necessarily make the accompanying algorithms any more difficult to write or to understand than the algorithms already studied. We will also discuss the important question, <em>“How much structural information ought to be explicitly recorded in memory?</em>”</p>

  <p class="indent">The problem we will consider arises in connection with writing a compiler program for the translation of COBOL and related languages. A programmer who uses COBOL may give alphabetic names to program variables on several levels; for example, the program might refer to files of data for sales and purchases, having the following structure:</p>

  <div class="equation"><a id="ch02eq-lev1sec4-1"></a><img src="../Images/ch02/424equ01.jpg"></div>

  <p>This configuration indicates that each item in <code>SALES</code> consists of two parts, the <code>DATE</code> and the <code>TRANSACTION</code>; the <code>DATE</code> is further divided into three parts, and the <code>TRANSACTION</code> likewise has five subdivisions. Similar remarks apply to <code>PURCHASES</code>. The relative order of these names indicates the order in which the quantities appear in external representations of the file (for example, magnetic tape or printed forms); notice that in this example “<code>DAY</code>” and “<code>MONTH</code>” appear in opposite order in the two files. The programmer also gives further information, not shown in this illustration, that tells how much space each item of information occupies and in what format it appears; such considerations are not relevant to us in this section, so they will not be mentioned further.</p>

  <p class="indent"><a id="page_425"></a>A COBOL programmer first describes the file layout and the other program variables, then specifies the algorithms that manipulate those quantities. To refer to an individual variable in the example above, it would not be sufficient merely to give the name <code>DAY</code>, since there is no way of telling if the variable called <code>DAY</code> is in the <code>SALES</code> file or in the <code>PURCHASES</code> file. Therefore a COBOL programmer is given the ability to write “<code>DAY OF SALES</code>” to refer to the <code>DAY</code> part of a <code>SALES</code> item. The programmer could also write, more completely,</p>

  <p class="center">“<code>DAY OF DATE OF SALES</code>”,</p>

  <p>but in general there is no need to give more qualification than necessary to avoid ambiguity. Thus,</p>

  <p class="center">“<code>NAME OF SHIPPER OF TRANSACTION OF PURCHASES</code>”</p>

  <p>may be abbreviated to</p>

  <p class="center">“<code>NAME OF SHIPPER</code>”</p>

  <p>since only one part of the data has been called <code>SHIPPER</code>.</p>

  <p class="indent">These rules of COBOL may be stated more precisely as follows:</p>

  <p class="indenthangingA">a) Each name is immediately preceded by an associated positive integer called its <em>level number</em>. A name either refers to an <em>elementary item</em> or it is the name of a <em>group</em> of one or more items whose names follow. In the latter case, each item of the group must have the same level number, which must be greater than the level number of the group name. (For example, <code>DATE</code> and <code>TRANSACTION</code> above have level number 2, which is greater than the level number 1 of <code>SALES</code>.)</p>

  <p class="indenthangingA">b) To refer to an elementary item or group of items named <em>A</em><sub>0</sub>, the general form is</p>

  <p class="center"><em>A</em><sub>0</sub><code>OF</code> <em>A</em><sub>1</sub><code>OF</code> ... <code>OF</code> <em>A</em><sub>n</sub>,</p>

  <p class="indenthangingAP">where <em>n</em> ≥ 0 and where, for 0 ≤ <em>j &lt; n</em>, <em>A</em><sub>j</sub> is the name of some item contained directly or indirectly within a group named <em>A</em><sub>j+1</sub> . There must be exactly one item <em>A</em><sub>0</sub> satisfying this condition.</p>

  <p class="indenthangingA">c) If the same name <em>A</em><sub>0</sub> appears in several places, there must be a way to refer to each use of the name by using qualification.</p>

  <p class="indenthangingAP">As an example of rule (c), the data configuration</p>

  <div class="equation"><a id="ch02eq-lev1sec4-2"></a><img src="../Images/ch02/425equ01.jpg"></div>

  <p>would not be allowed, since there is no unambiguous way to refer to the second appearance of <code>CC</code>. (See <a href="../Text/ch02c.html#ch02ex_1_4_4">exercise 4</a>.)</p>

  <p class="indent"><a id="page_426"></a>COBOL has another feature that affects compiler writing and the application we are considering, namely an option in the language that makes it possible to refer to many items at once. A COBOL programmer may write</p>

  <p class="center"><code>MOVE CORRESPONDING</code> <em>α</em> <code>TO</code> <em>β</em></p>

  <p>which moves all items with corresponding names from data area <em>α</em> to data area <em>β</em>. For example, the COBOL statement</p>

  <p class="center"><code>MOVE CORRESPONDING DATE OF SALES TO DATE OF PURCHASES</code></p>

  <p>would mean that the values of <code>MONTH</code>, <code>DAY</code>, and <code>YEAR</code> from the <code>SALES</code> file are to be moved to the variables <code>MONTH</code>, <code>DAY</code>, and <code>YEAR</code> in the <code>PURCHASES</code> file. (The relative order of <code>DAY</code> and <code>MONTH</code> is thereby interchanged.)</p>

  <p class="indent">The problem we will investigate in this section is to design three algorithms suitable for use in a COBOL compiler, which are to do the following things:</p>

  <p class="indent"><strong>Operation 1</strong>. To process a description of names and level numbers such as (<a href="../Text/ch02c.html#ch02eq-lev1sec4-1">1</a>), putting the relevant information into tables within the compiler for use in operations 2 and 3.</p>

  <p class="indent"><strong>Operation 2</strong>. To determine if a given qualified reference, as in rule (b), is valid, and when it is valid to locate the corresponding data item.</p>

  <p class="indent"><strong>Operation 3</strong>. To find all corresponding pairs of items indicated by a given <code>CORRESPONDING</code> statement.</p>

  <p class="indent">We will assume that our compiler already has a “symbol table subroutine” that will convert an alphabetic name into a link that points to a table entry for that name. (Methods for constructing symbol table algorithms are discussed in detail in Chapter 6.) In addition to the Symbol Table, there is a larger table that contains one entry for each item of data in the COBOL source program that is being compiled; we will call this the <em>Data Table</em>.</p>

  <p class="indent">Clearly, we cannot design an algorithm for operation 1 until we know what kind of information is to be stored in the Data Table, and the form of the Data Table depends on what information we need in order to perform operations 2 and 3; thus we look first at operations 2 and 3.</p>

  <p class="indent">In order to determine the meaning of the COBOL reference</p>

  <div class="equation"><a id="ch02eq-lev1sec4-3"></a><img src="../Images/ch02/426equ01.jpg"></div>

  <p>we should first look up the name <em>A</em><sub>0</sub> in the Symbol Table. There ought to be a series of links from the Symbol Table entry to all Data Table entries for this name. Then for each Data Table entry we will want a link to the entry for the group item that contains it. Now if there is a further link field from the Data Table items back to the Symbol Table, it is not hard to see how a reference like (<a href="../Text/ch02c.html#ch02eq-lev1sec4-3">3</a>) can be processed. Furthermore, we will want some sort of links from the Data Table entries for group items to the items in the group, in order to locate the pairs indicated by “<code>MOVE CORRESPONDING</code>”.</p>

  <p class="indent"><a id="page_427"></a>We have thereby found a potential need for five link fields in each Data Table entry:</p>

  <p class="uln-indent"><code>PREV</code> (a link to the previous entry with the same name, if any);</p>

  <p class="uln-indent"><code>PARENT</code> (a link to the smallest group, if any, containing this item);</p>

  <p class="uln-indent"><code>NAME</code> (a link to the Symbol Table entry for this item);</p>

  <p class="uln-indent"><code>CHILD</code> (a link to the first subitem of a group);</p>

  <p class="uln-indent"><code>SIB</code> (a link to the next subitem in the group containing this item).</p>

  <p>It is clear that COBOL data structures like those for <code>SALES</code> and <code>PURCHASES</code> above are essentially trees; and the <code>PARENT</code>, <code>CHILD</code>, and <code>SIB</code> links that appear here are familiar from our previous study. (The conventional binary tree representation of a tree consists of the <code>CHILD</code> and <code>SIB</code> links; adding the <code>PARENT</code> link gives what we have called a “triply linked tree.” The five links above consist of these three tree links together with <code>PREV</code> and <code>NAME</code>, which superimpose further information on the tree structure.)</p>

  <p class="indent">Perhaps not all five of these links will turn out to be necessary, or sufficient, but we will try first to design our algorithms under the tentative assumption that Data Table entries will involve these five link fields (plus further information irrelevant to our problems). As an example of the multiple linking used, consider the two COBOL data structures</p>

  <div class="equation"><a id="ch02eq-lev1sec4-4"></a><img src="../Images/ch02/427equ01.jpg"></div>

  <p>They would be represented as shown in (<a href="../Text/ch02c.html#ch02eq-lev1sec4-5">5</a>) (with links indicated symbolically). The <code>LINK</code> field of each Symbol Table entry points to the most recently encountered Data Table entry for the symbolic name in question.</p>

  <p class="indent">The first algorithm we require is one that builds the Data Table in such a form. Note the flexibility in choice of level numbers that is allowed by the COBOL rules; the left structure in (<a href="../Text/ch02c.html#ch02eq-lev1sec4-4">4</a>) is completely equivalent to</p>

  <div class="image"><img src="../Images/ch02/e427_01.jpg"></div>

  <p>because level numbers do not have to be sequential.</p>

  <div class="equation"><a id="page_428"></a><a id="ch02eq-lev1sec4-5"></a><img src="../Images/ch02/428equ01.jpg"></div>

  <p class="indent">Some sequences of level numbers are illegal, however; for example, if the level number of <code>D</code> in (<a href="../Text/ch02c.html#ch02eq-lev1sec4-4">4</a>) were changed to “<code>6</code>” (in either place) we would have a meaningless data configuration, violating the rule that all items of a group must have the same number. The following algorithm therefore makes sure that COBOL’s rule (a) has not been broken.</p>

  <p><a id="ch02alg-lev1sec4-A"></a><strong>Algorithm A</strong> (<em>Build Data Table</em>). This algorithm is given a sequence of pairs (<code>L</code><em>,</em> <code>P</code>), where <code>L</code> is a positive integer “level number” and <code>P</code> points to a Symbol Table entry, corresponding to COBOL data structures such as (<a href="../Text/ch02c.html#ch02eq-lev1sec4-4">4</a>) above. The algorithm builds a Data Table as in the example (<a href="../Text/ch02c.html#ch02eq-lev1sec4-5">5</a>) above. When <code>P</code> points to a Symbol Table entry that has not appeared before, <code>LINK(P)</code> will equal Λ. This algorithm uses an auxiliary stack that is treated as usual (using either sequential memory allocation, as in <a href="../Text/ch02.html#ch02lev2sec2">Section 2.2.2</a>, or linked allocation, as in <a href="../Text/ch02.html#ch02lev2sec3">Section 2.2.3</a>).</p>

  <p class="indenthanging"><strong>A1.</strong> [Initialize.] Set the stack contents to the single entry (0<em>,</em> Λ). (The stack entries throughout this algorithm are pairs (<code>L</code><em>,</em> <code>P</code>), where <code>L</code> is an integer and <code>P</code> is a pointer; as this algorithm proceeds, the stack contains the level numbers and pointers to the most recent data entries on all levels higher in the tree than the current level. For example, just before encountering the pair “<code>3 F</code>” in the example above, the stack would contain</p>

  <p class="center">(0<em>,</em> <em>Λ</em>)&nbsp;&nbsp;&nbsp;(1<em>,</em> A1)&nbsp;&nbsp;&nbsp;(3<em>,</em> E3)</p>

  <p class="indenthangingAP">from bottom to top.)</p>

  <p class="indenthanging"><a id="page_429"></a><strong>A2.</strong> [Next item.] Let (<code>L</code><em>,</em> <code>P</code>) be the next data item from the input. If the input is exhausted, however, the algorithm terminates. Set <code>Q</code> <span class="ent">⇐</span> <code>AVAIL</code> (that is, let <code>Q</code> be the location of a new node in which we can put the next Data Table entry).</p>

  <p class="indenthanging"><strong>A3.</strong> [Set name links.] Set</p>

  <p class="center"><code>PREV(Q)</code> ← <code>LINK(P)</code><em>,</em>&nbsp;&nbsp;&nbsp;&nbsp;<code>LINK(P)</code> ← <code>Q</code><em>,</em>&nbsp;&nbsp;&nbsp;&nbsp;<code>NAME(Q)</code> ← <code>P</code>.</p>

  <p class="indenthangingAP">(This properly sets two of the five links in <code>NODE(Q)</code>. We now want to set <code>PARENT</code>, <code>CHILD</code>, and <code>SIB</code> appropriately.)</p>

  <p class="indenthanging"><strong>A4.</strong> [Compare levels.] Let the top entry of the stack be (<code>L1</code><em>,</em> <code>P1</code>). If <code>L1</code> &lt; <code>L</code>, set <code>CHILD(P1)</code> ← <code>Q</code> (or, if <code>P1</code> = <em>Λ</em>, set <code>FIRST</code> ← <code>Q</code>, where <code>FIRST</code> is a variable that will point to the first Data Table entry) and go to A6.</p>

  <p class="indenthanging"><strong>A5.</strong> [Remove top level.] If <code>L1</code> &gt; <code>L</code>, remove the top stack entry, let (<code>L1</code><em>,</em> <code>P1</code>) be the new entry that has just come to the top of the stack, and repeat step A5. If <code>L1</code> &lt; <code>L</code>, signal an error (mixed numbers have occurred on the same level). Otherwise, namely when <code>L1</code> = <code>L</code>, set <code>SIB(P1)</code> ← <code>Q</code>, remove the top stack entry, and let (<code>L1</code><em>,</em> <code>P1</code>) be the pair that has just come to the top of the stack.</p>

  <p class="indenthanging"><strong>A6.</strong> [Set family links.] Set <code>PARENT(Q)</code> ← <code>P1</code>, <code>CHILD(Q)</code> ← <em>Λ</em>, <code>SIB(Q)</code> ← <em>Λ</em>.</p>

  <p class="indenthanging"><strong>A7.</strong> [Add to stack.] Place (<code>L</code><em>,</em> <code>Q</code>) on top of the stack, and return to step A2. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent">The introduction of an auxiliary stack, as explained in step A1, makes this algorithm so transparent that it needs no further explanation.</p>

  <p class="indent">The next problem is to locate the Data Table entry corresponding to a reference</p>

  <div class="equation"><a id="ch02eq-lev1sec4-6"></a><img src="../Images/ch02/429equ01.jpg"></div>

  <p>A good compiler will also check to ensure that such a reference is unambiguous. In this case, a suitable algorithm suggests itself immediately: All we need to do is to run through the list of Data Table entries for the name <em>A</em><sub>0</sub> and make sure that exactly one of these entries matches the stated qualification <em>A</em><sub>1</sub><em>, ..., A<sub>n</sub></em>.</p>

  <p><a id="ch02alg-lev1sec4-B"></a><strong>Algorithm B</strong> (<em>Check a qualified reference</em>). Corresponding to reference (<a href="../Text/ch02c.html#ch02eq-lev1sec4-6">6</a>), a Symbol Table subroutine will find pointers <em>P</em><sub>0</sub><em>, P</em><sub>1</sub><em>, ..., P<sub>n</sub></em> to the Symbol Table entries for <em>A</em><sub>0</sub><em>, A</em><sub>1</sub><em>, ..., A<sub>n</sub></em>, respectively.</p>

  <p class="indent">The purpose of this algorithm is to examine <em>P</em><sub>0</sub><em>, P</em><sub>1</sub><em>, ..., P<sub>n</sub></em> and either to determine that reference (<a href="../Text/ch02c.html#ch02eq-lev1sec4-6">6</a>) is in error, or to set variable <code>Q</code> to the address of the Data Table entry for the item referred to by (<a href="../Text/ch02c.html#ch02eq-lev1sec4-6">6</a>).</p>

  <p class="indenthanging"><strong>B1.</strong> [Initialize.] Set <code>Q</code> ← <em>Λ</em>, <code>P</code> ← <code>LINK(</code><em>P</em><sub>0</sub><code>)</code>.</p>

  <p class="indenthanging"><strong>B2.</strong> [Done?] If <code>P</code> = <em>Λ</em>, the algorithm terminates; at this point <code>Q</code> will equal <em>Λ</em> if (<a href="../Text/ch02c.html#ch02eq-lev1sec4-6">6</a>) does not correspond to any Data Table entry. But if <code>P</code> ≠ <em>Λ</em>, set <code>S</code> ← <code>P</code> and <em>k</em> ← 0. (<code>S</code> is a pointer variable that will run from <code>P</code> up the tree through <code>PARENT</code> links; <em>k</em> is an integer variable that goes from 0 to <em>n</em>. In practice, the pointers <em>P</em><sub>0</sub><em>, ..., P<sub>n</sub></em> would often be kept in a linked list, and instead of <em>k</em>, we would substitute a pointer variable that traverses this list; see <a href="../Text/ch02c.html#ch02ex_1_4_5">exercise 5</a>.)</p>

  <p class="indenthanging"><a id="page_430"></a><strong>B3.</strong> [Match complete?] If <em>k &lt; n</em> go on to B4. Otherwise we have found a matching Data Table entry; if <code>Q</code> ≠ <em>Λ</em>, this is the second entry found, so an error condition is signaled. Set <code>Q</code> ← <code>P</code>, <code>P</code> ← <code>PREV(P)</code>, and go to B2.</p>

  <p class="indenthanging"><strong>B4.</strong> [Increase <em>k</em>.] Set <em>k ← k</em> + 1.</p>

  <p class="indenthanging"><strong>B5.</strong> [Move up tree.] Set <code>S</code> ← <code>PARENT(S)</code>. If <code>S</code> = <em>Λ</em>, we have failed to find a match; set <code>P</code> ← <code>PREV(P)</code> and go to B2.</p>

  <p class="indenthanging"><strong>B6.</strong> [<em>A<sub>k</sub></em> match?] If <code>NAME(S)</code> = <em>P<sub>k</sub></em>, go to B3, otherwise go to B5. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p>Note that the <code>CHILD</code> and <code>SIB</code> links are not needed by this algorithm.</p>

  <div class="image">
    <a id="ch02fig40"></a><img src="../Images/ch02/02fig40.jpg">

    <p class="fig-caption"><strong>Fig. 40.</strong> Algorithm for checking a COBOL reference.</p>
  </div>

  <p class="indent">The third and final algorithm that we need concerns “<code>MOVE CORRESPONDING</code>”; before we design such an algorithm, we must have a precise definition of what is required. The COBOL statement</p>

  <div class="equation"><a id="ch02eq-lev1sec4-7"></a><img src="../Images/ch02/430equ01.jpg"></div>

  <p>where <em>α</em> and <em>β</em> are references such as (<a href="../Text/ch02c.html#ch02eq-lev1sec4-6">6</a>) to data items, is an abbreviation for the set of all statements</p>

  <p class="center"><code>MOVE</code> <em>α</em>′ <code>TO</code> <em>β</em>′</p>

  <p>where there exists an integer <em>n</em> ≥ 0 and <em>n</em> names <em>A</em><sub>0</sub><em>, A</em><sub>1</sub><em>, ..., A<sub>n−</sub></em><sub>1</sub> such that</p>

  <div class="equation"><a id="ch02eq-lev1sec4-8"></a><img src="../Images/ch02/430equ02.jpg"></div>

  <p>and either <em>α</em>′ or <em>β</em>′ is an elementary item (not a group item). Furthermore we require that the first levels of (<a href="../Text/ch02c.html#ch02eq-lev1sec4-8">8</a>) show <em>complete</em> qualifications, namely that <em>A<sub>j</sub></em><sub>+1</sub> be the parent of <em>A<sub>j</sub></em> for 0 <em>≤ j &lt; n</em> − 1 and that <em>α</em> and <em>β</em> are parents of <em>A<sub>n−</sub></em><sub>1</sub>; <em>α</em>′ and <em>β</em>′ must be exactly <em>n</em> levels farther down in the tree than <em>α</em> and <em>β</em> are.</p>

  <p class="indent">With respect to our example (<a href="../Text/ch02c.html#ch02eq-lev1sec4-4">4</a>),</p>

  <p class="center"><code>MOVE CORRESPONDING A TO H</code></p>

  <p>is therefore an abbreviation for the statements</p>

  <p class="uln-indent1"><code>MOVE B OF A TO B OF H</code><br>
  <code>MOVE G OF F OF A TO G OF F OF H</code></p>

  <p class="indent">The algorithm to recognize all corresponding pairs <em>α</em>′, <em>β</em>′ is quite interesting although not difficult; we move through the tree whose root is <em>α</em>, in preorder, <a id="page_431"></a>simultaneously looking in the <em>β</em> tree for matching names, and skipping over subtrees in which no corresponding elements can possibly occur. The names <em>A</em><sub>0</sub><em>, ..., A<sub>n−</sub></em><sub>1</sub> of (<a href="../Text/ch02c.html#ch02eq-lev1sec4-8">8</a>) are discovered in the opposite order <em>A<sub>n−</sub></em><sub>1</sub><em>, ..., A</em><sub>0</sub>.</p>

  <p><a id="ch02alg-lev1sec4-C"></a><strong>Algorithm C</strong> (<em>Find</em> <code>CORRESPONDING</code> <em>pairs</em>). Given <code>P0</code> and <code>Q0</code>, which point to Data Table entries for <em>α</em> and <em>β</em>, respectively, this algorithm successively finds all pairs (<code>P</code><em>,</em> <code>Q</code>) of pointers to items (α′, <em>β</em>′) satisfying the constraints mentioned above.</p>

  <p class="indenthanging"><strong>C1.</strong> [Initialize.] Set <code>P</code> ← <code>P0</code>, <code>Q</code> ← <code>Q0</code>. (In the remainder of this algorithm, the pointer variables <code>P</code> and <code>Q</code> will walk through trees having the respective roots <em>α</em> and <em>β</em>.)</p>

  <p class="indenthanging"><strong>C2.</strong> [Elementary?] If <code>CHILD(P)</code> = <em>Λ</em> or <code>CHILD(Q)</code> = <em>Λ</em>, output (<code>P</code><em>,</em> <code>Q</code>) as one of the desired pairs and go to C5. Otherwise set <code>P</code> ← <code>CHILD(P)</code>, <code>Q</code> ← <code>CHILD(Q)</code>. (In this step, <code>P</code> and <code>Q</code> point to items <em>α</em>′ and <em>β</em>′ satisfying (<a href="../Text/ch02c.html#ch02eq-lev1sec4-8">8</a>), and we wish to <code>MOVE</code> <em>α</em>′ <code>TO</code> <em>β</em>′ if and only if either <em>α</em>′ or <em>β</em>′ (or both) is an elementary item.)</p>

  <p class="indenthanging"><strong>C3.</strong> [Match name.] (Now <code>P</code> and <code>Q</code> point to data items that have respective complete qualifications of the forms</p>

  <p class="center"><em>A</em><sub>0</sub><code>OF</code> <em>A</em><sub>1</sub><code>OF</code> <em>...</em> <code>OF</code> <em>A<sub>n−</sub></em><sub>1</sub><code>OF</code> <em>α</em></p>

  <p class="indenthangingAP">and</p>

  <p class="center"><em>B</em><sub>0</sub><code>OF</code> <em>A</em><sub>1</sub><code>OF</code> <em>...</em> <code>OF</code> <em>A<sub>n−</sub></em><sub>1</sub><code>OF</code> <em>β</em>.</p>

  <p class="indenthangingAP">The object is to see if we can make <em>B</em><sub>0</sub> = <em>A</em><sub>0</sub> by examining all the names of the group <em>A</em><sub>1</sub><code>OF</code> <em>...</em> <code>OF</code> <em>A<sub>n−</sub></em><sub>1</sub><code>OF</code> <em>β</em>.) If <code>NAME(P)</code> = <code>NAME(Q)</code>, go to C2 (a match has been found). Otherwise, if <code>SIB(Q)</code> ≠ <em>Λ</em>, set <code>Q</code> ← <code>SIB(Q)</code> and repeat step C3. (If <code>SIB(Q)</code> = <em>Λ</em>, no matching name is present in the group, and we continue on to step C4.)</p>

  <p class="indenthanging"><strong>C4.</strong> [Move on.] If <code>SIB(P)</code> ≠ <em>Λ</em>, set <code>P</code> ← <code>SIB(P)</code> and <code>Q</code> ← <code>CHILD(PARENT(Q))</code>, and go back to C3. If <code>SIB(P)</code> = <em>Λ</em>, set <code>P</code> ← <code>PARENT(P)</code> and <code>Q</code> ← <code>PARENT(Q)</code>.</p>

  <p class="indenthanging"><strong>C5.</strong> [Done?] If <code>P</code> = <code>P0</code>, the algorithm terminates; otherwise go to C4. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p>A flow chart for this algorithm is shown in <a href="../Text/ch02c.html#ch02fig41">Fig. 41</a>. A proof that this algorithm is valid can readily be constructed by induction on the size of the trees involved (see <a href="../Text/ch02c.html#ch02ex_1_4_9">exercise 9</a>).</p>

  <div class="image">
    <a id="ch02fig41"></a><img src="../Images/ch02/02fig41.jpg">

    <p class="fig-caption"><strong>Fig. 41.</strong> Algorithm for “<code>MOVE CORRESPONDING</code>”.</p>
  </div>

  <p class="indent"><a id="page_432"></a>At this point it is worthwhile to study the ways in which the five link fields <code>PREV</code>, <code>PARENT</code>, <code>NAME</code>, <code>CHILD</code>, and <code>SIB</code> are used by <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a>. The striking feature is that these five links constitute a “complete set” in the sense that <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a> do virtually the minimum amount of work as they move through the Data Table. Whenever they need to refer to another Data Table entry, its address is immediately available; there is no need to conduct a search. It would be difficult to imagine how <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a> could possibly be made any faster if any additional link information were present in the table. (See <a href="../Text/ch02c.html#ch02ex_1_4_11">exercise 11</a>, however.)</p>

  <p class="indent">Each link field may be viewed as a <em>clue</em> to the program, planted there in order to make the algorithms run faster. (Of course, the algorithm that builds the tables, <a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a>, runs correspondingly slower, since it has more links to fill in. But table-building is done only once.) It is clear, on the other hand, that the Data Table constructed above contains much redundant information. Let us consider what would happen if we were to <em>delete</em> certain of the link fields.</p>

  <p class="indent">The <code>PREV</code> link, while not used in <a href="../Text/ch02c.html#ch02alg-lev1sec4-C">Algorithm C</a>, is extremely important for <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a>, and it seems to be an essential part of any COBOL compiler unless lengthy searches are to be carried out. A field that links together all items of the same name therefore seems essential for efficiency. We could perhaps modify the strategy slightly and adopt circular linking instead of terminating each list with <em>Λ</em>, but there is no reason to do this unless other link fields are changed or eliminated.</p>

  <p class="indent">The <code>PARENT</code> link is used in both <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a>, although its use in <a href="../Text/ch02c.html#ch02alg-lev1sec4-C">Algorithm C</a> could be avoided if we used an auxiliary stack in that algorithm, or if we augmented <code>SIB</code> so that thread links are included (as in <a href="../Text/ch02a.html#ch02lev2sec8">Section 2.3.2</a>). So we see that the <code>PARENT</code> link has been used in an essential way only in <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a>. If the <code>SIB</code> link were threaded, so that the items that now have <code>SIB</code> = <em>Λ</em> would have <code>SIB</code> = <code>PARENT</code> instead, it would be possible to locate the parent of any data item by following the <code>SIB</code> links; the added thread links could be distinguished either by having a new <code>TAG</code> field in each node that says whether the <code>SIB</code> link is a thread, or by the condition “<code>SIB(P)</code> &lt; <code>P</code>” if the Data Table entries are kept consecutively in memory in order of appearance. This would mean a short search would be necessary in step B5, and the algorithm would be correspondingly slower.</p>

  <p class="indent">The <code>NAME</code> link is used by the algorithms only in steps B6 and C3. In both cases we could make the tests “<code>NAME(S)</code> = <em>P<sub>k</sub></em>” and “<code>NAME(P)</code> = <code>NAME(Q)</code>” in other ways if the <code>NAME</code> link were not present (see <a href="../Text/ch02c.html#ch02ex_1_4_10">exercise 10</a>), but this would significantly slow down the inner loops of both <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a>. Here again we see a trade-off between the space for a link and the speed of the algorithms. (The speed of <a href="../Text/ch02c.html#ch02alg-lev1sec4-C">Algorithm C</a> is not especially significant in COBOL compilers, when typical uses of <code>MOVE CORRESPONDING</code> are considered; but <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a> should be fast.) Experience indicates that other important uses are found for the <code>NAME</code> link within a COBOL compiler, especially in printing diagnostic information.</p>

  <p class="indent"><a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a> builds the Data Table step by step, and it never has occasion to return a node to the pool of available storage; so we usually find that Data Table entries take consecutive memory locations in the order of appearance of <a id="page_433"></a>the data items in the COBOL source program. Thus in our example (<a href="../Text/ch02c.html#ch02eq-lev1sec4-5">5</a>), locations A1, B3, <em>...</em> would follow each other. This sequential nature of the Data Table leads to certain simplifications; for example, the <code>CHILD</code> link of each node is either <em>Λ</em> or it points to the node immediately following, so <code>CHILD</code> can be reduced to a 1-bit field. Alternatively, <code>CHILD</code> could be removed in favor of a test if <code>PARENT(P</code> + <em>c</em><code>)</code> = <code>P</code>, where <em>c</em> is the node size in the Data Table.</p>

  <p class="indent">Thus the five link fields are not all essential, although they are helpful from the standpoint of speed in <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a>. This situation is fairly typical of most multilinked structures.</p>

  <p class="indent">It is interesting to note that at least half a dozen people writing COBOL compilers in the early 1960s arrived independently at this same way to maintain a Data Table using five links (or four of the five, usually with the <code>CHILD</code> link missing). The first publication of such a technique was by H. W. Lawson, Jr. [<em>ACM National Conference Digest</em> (Syracuse, N.Y.: 1962)]. But in 1965 an ingenious technique for achieving the effects of <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">Algorithms B</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-C">C</a>, using only two link fields and sequential storage of the Data Table, without a very great decrease in speed, was introduced by David Dahm; see <a href="../Text/ch02c.html#ch02ex_1_4_12">exercises 12</a> through <a href="../Text/ch02c.html#ch02ex_1_4_14">14</a>.</p>

  <p class="ex-title">Exercises</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_1a" id="ch02ex_1_4_1">1</a>.</strong> [<em>00</em>] Considering COBOL data configurations as tree structures, are the data items listed by a COBOL programmer in preorder, postorder, or neither of those orders?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_2a" id="ch02ex_1_4_2">2</a>.</strong> [<em>10</em>] Comment about the running time of <a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a>.</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_3a" id="ch02ex_1_4_3">3</a>.</strong> [<em>22</em>] The PL/I language accepts data structures like those in COBOL, except that any sequence of level numbers is possible. For example, the sequence</p>

  <div class="image"><img src="../Images/ch02/e433_01.jpg"></div>

  <p class="exercisesp">In general, rule (a) is modified to read, “The items of a group must have a sequence of nonincreasing level numbers, all of which are greater than the level number of the group name.” What modifications to <a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a> would change it from the COBOL convention to this PL/I convention?</p>

  <p class="exercises2"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_4_4a" id="ch02ex_1_4_4">4</a>.</strong> [<em>26</em>] <a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a> does not detect the error if a COBOL programmer violates rule (c) stated in the text. How should <a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a> be modified so that only data structures satisfying rule (c) will be accepted?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_5a" id="ch02ex_1_4_5">5</a>.</strong> [<em>20</em>] In practice, <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a> may be given a linked list of Symbol Table references as input, instead of what we called “<em>P</em><sub>0</sub><em>, P</em><sub>1</sub><em>, ..., P<sub>n</sub></em>.” Let <code>T</code> be a pointer variable such that</p>

  <p class="exercisesp"><code>INFO(T)</code> <em>≡ P</em><sub>0</sub><em>,</em> <code>INFO(RLINK(T))</code> <em>≡ P</em><sub>1</sub><em>, ...,</em> <code>INFO(RLINK</code><sup>[<em>n</em>]</sup><code>(T))</code> <em>≡ P<sub>n</sub>,</em> <code>RLINK</code><sup>[<em>n</em>+1]</sup><code>(T)</code> = <em>Λ</em>. Show how to modify <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a> so that it uses such a linked list as input.</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_6a" id="ch02ex_1_4_6">6</a>.</strong> [<em>23</em>] The PL/I language accepts data structures much like those in COBOL, but does not make the restriction of rule (c); instead, we have the rule that a qualified reference (<a href="../Text/ch02c.html#ch02eq-lev1sec4-3">3</a>) is unambiguous if it shows “complete” qualification — that is, if <em>A<sub>j</sub></em><sub>+1</sub> is <a id="page_434"></a>the parent of <em>A<sub>j</sub></em> for 0 <em>≤ j &lt; n</em>, and if <em>A<sub>n</sub></em> has no parent. Rule (c) is now weakened to the simple condition that no two items of a group may have the same name. The second “<code>CC</code>” in (<a href="../Text/ch02c.html#ch02eq-lev1sec4-2">2</a>) would be referred to as “<code>CC OF AA</code>” without ambiguity; the three data items</p>

  <p class="center"><code>1 A</code><br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>2 A</code><br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>3 A</code></p>

  <p class="exercisesp">would be referred to as “<code>A</code>”, “<code>A OF A</code>”, “<code>A OF A OF A</code>” with respect to the PL/I convention just stated. [<em>Note:</em> Actually the word “<code>OF</code>” is replaced by a period in PL/I, and the order is reversed; “<code>CC OF AA</code>” is really written “<code>AA.CC</code>” in PL/I, but this is not important for the purposes of the present exercise.] Show how to modify <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a> so that it follows the PL/I convention.</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_7a" id="ch02ex_1_4_7">7</a>.</strong> [<em>15</em>] Given the data structures in (<a href="../Text/ch02c.html#ch02eq-lev1sec4-1">1</a>), what does the COBOL statement “<code>MOVE CORRESPONDING SALES TO PURCHASES</code>” mean?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_8a" id="ch02ex_1_4_8">8</a>.</strong> [<em>10</em>] Under what circumstances is “<code>MOVE CORRESPONDING</code> <em>α</em> <code>TO</code> <em>β</em>” exactly the same as “<code>MOVE</code> <em>α</em> <code>TO</code> <em>β</em>”, according to the definition in the text?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_4_9a" id="ch02ex_1_4_9">9</a>.</strong> [<em>M23</em>] Prove that <a href="../Text/ch02c.html#ch02alg-lev1sec4-C">Algorithm C</a> is correct.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_4_10a" id="ch02ex_1_4_10">10</a>.</strong> [<em>23</em>] (a) How could the test “<code>NAME(S)</code> = <em>P<sub>k</sub></em>” in step B6 be performed if there were no <code>NAME</code> link in the Data Table nodes? (b) How could the test “<code>NAME(P)</code> = <code>NAME(Q)</code>” in step C3 be performed if there were no <code>NAME</code> link in the Data Table entries? (Assume that all other links are present as in the text.)</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_4_11a" id="ch02ex_1_4_11">11</a>.</strong> [<em>23</em>] What additional links or changes in the strategy of the algorithms of the text could make <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a> or <a href="../Text/ch02c.html#ch02alg-lev1sec4-C">Algorithm C</a> faster?</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_4_12a" id="ch02ex_1_4_12">12</a>.</strong> [<em>25</em>] (D. M. Dahm.) Consider representing the Data Table in sequential locations with just two links for each item:</p>

  <p class="uln-indent1"><code>PREV</code> (as in the text);<br>
  <code>SCOPE</code> (a link to the last elementary item in this group).</p>

  <p class="exercisesp">We have <code>SCOPE(P)</code> = <code>P</code> if and only if <code>NODE(P)</code> represents an elementary item. For example, the Data Table of (<a href="../Text/ch02c.html#ch02eq-lev1sec4-5">5</a>) would be replaced by</p>

  <div class="image"><img src="../Images/ch02/434pro02.jpg"></div>

  <p class="exercisesp">(Compare with (<a href="../Text/ch02c.html#ch02eq-lev1sec4-5">5</a>) of <a href="../Text/ch02a.html#ch02lev2sec9">Section 2.3.3</a>.) Notice that <code>NODE(P)</code> is part of the tree below <code>NODE(Q)</code> if and only if <code>Q</code> &lt; <code>P</code> ≤ <code>SCOPE(Q)</code>. Design an algorithm that performs the function of <a href="../Text/ch02c.html#ch02alg-lev1sec4-B">Algorithm B</a> when the Data Table has this format.</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_4_13a" id="ch02ex_1_4_13">13</a>.</strong> [<em>24</em>] Give an algorithm to substitute for <a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a> when the Data Table is to have the format shown in <a href="../Text/ch02c.html#ch02ex_1_4_12">exercise 12</a>.</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_4_14a" id="ch02ex_1_4_14">14</a>.</strong> [<em>28</em>] Give an algorithm to substitute for <a href="../Text/ch02c.html#ch02alg-lev1sec4-C">Algorithm C</a> when the Data Table has the format shown in <a href="../Text/ch02c.html#ch02ex_1_4_12">exercise 12</a>.</p>

  <p class="exercises1"><strong><a id="ch02ex_1_4_15"></a>15.</strong> [<em>25</em>] (David S. Wise.) Reformulate <a href="../Text/ch02c.html#ch02alg-lev1sec4-A">Algorithm A</a> so that no extra storage is used for the stack. [<em>Hint:</em> The <code>SIB</code> fields of all nodes pointed to by the stack are <em>Λ</em> in the present formulation.]</p>

  <div class="heading">
    <h3 id="ch02lev1sec5"><a id="page_435"></a>2.5. Dynamic Storage Allocation</h3>

    <p>We Have Seen how the use of links implies that data structures need not be sequentially located in memory; a number of tables may independently grow and shrink in a common pooled memory area. However, our discussions have always tacitly assumed that all nodes have the same size — that every node occupies a certain fixed number of memory cells.</p>
  </div>

  <p class="indent">For a great many applications, a suitable compromise can be found so that a uniform node size is indeed used for all structures (for example, see <a href="../Text/ch02c.html#ch02ex_1_5_2">exercise 2</a>). Instead of simply taking the maximum size that is needed and wasting space in smaller nodes, it is customary to pick a rather small node size and to employ what may be called the classical <em>linked-memory philosophy</em>: “If there isn’t room for the information here, let’s put it somewhere else and plant a link to it.”</p>

  <p class="indent">For a great many other applications, however, a single node size is not reasonable; we often wish to have nodes of varying sizes sharing a common memory area. Putting this another way, we want algorithms for reserving and freeing variable-size blocks of memory from a larger storage area, where these blocks are to consist of consecutive memory locations. Such techniques are generally called <em>dynamic storage allocation</em> algorithms.</p>

  <p class="indent">Sometimes, often in simulation programs, we want dynamic storage allocation for nodes of rather small sizes (say one to ten words); and at other times, often in operating systems, we are dealing primarily with rather large blocks of information. These two points of view lead to slightly different approaches to dynamic storage allocation, although the methods have much in common. For uniformity in terminology between these two approaches, we will generally use the terms <em>block</em> and <em>area</em> rather than “node” in this section, to denote a set of contiguous memory locations.</p>

  <p class="indent">In 1975 or so, several authors began to call the pool of available memory a “heap.” But in the present series of books, we will use that word only in its more traditional sense related to priority queues (see Section 5.2.3).</p>

  <p><strong>A. Reservation.</strong> <a href="../Text/ch02c.html#ch02fig42">Figure 42</a> shows a typical <em>memory map</em> or “checkerboard,” a chart showing the current state of some memory pool. In this case the memory is shown partitioned into 53 blocks of storage that are “reserved,” or in use, mixed together with 21 “free” or “available” blocks that are not in use. After dynamic storage allocation has been in operation for awhile, the computer memory will perhaps look something like this. Our first problem is to answer two questions:</p>

  <p class="indenthangingA">a) How is this partitioning of available space to be represented inside the computer?</p>

  <p class="indenthangingA">b) Given such a representation of the available spaces, what is a good algorithm for finding a block of <em>n</em> consecutive free spaces and reserving them?</p>

  <div class="image">
    <a id="page_436"></a><a id="ch02fig42"></a><img src="../Images/ch02/02fig42.jpg">

    <p class="fig-caption"><strong>Fig. 42.</strong> A memory map.</p>
  </div>

  <p class="indent">The answer to question (a) is, of course, to keep a <em>list</em> of the available space somewhere; this is almost always done best by using the available space <em>itself</em> to contain such a list. (An exception is the case when we are allocating storage for a disk file or other memory in which nonuniform access time makes it better to maintain a separate directory of available space.)</p>

  <p class="indent">Thus, we can <em>link together</em> the available segments: The first word of each free storage area can contain the size of that block and the address of the next free area. The free blocks can be linked together in increasing or decreasing order of size, or in order of memory address, or in essentially random order.</p>

  <p class="indent">For example, consider <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a>, which illustrates a memory of 131,072 words, addressed from 0 to 131071. If we were to link together the available blocks in order of memory location, we would have one variable <code>AVAIL</code> pointing to the first free block (in this case <code>AVAIL</code> would equal 0), and the other blocks would be represented as follows:</p>

  <div class="image"><img src="../Images/ch02/436pro01.jpg"></div>

  <p>Thus locations 0 through 100 form the first available block; after the reserved areas 101–290 and 291–631 shown in <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a>, we have more free space in location 632–673; etc.</p>

  <p class="indent">As for question (b), if we want <em>n</em> consecutive words, clearly we must locate some block of <em>m ≥ n</em> available words and reduce its size to <em>m − n</em>. (Furthermore, when <em>m</em> = <em>n</em>, we must also delete this block from the list.) There may be several blocks with <em>n</em> or more cells, and so the question becomes, <em>which</em> area should be chosen?</p>

  <p class="indent">Two principal answers to this question suggest themselves: We can use the <em>best-fit method</em> or the <em>first-fit method</em>. In the former case, we decide to choose an area with <em>m</em> cells, where <em>m</em> is the smallest value present that is <em>n</em> or more. This might require searching the entire list of available space before a decision can be made. The first-fit method, on the other hand, simply chooses the first area encountered that has <em>≥ n</em> words.</p>

  <p class="indent">Historically, the best-fit method was widely used for several years; this naturally appears to be a good policy since it saves the larger available areas <a id="page_437"></a>for a later time when they might be needed. But several objections to the best-fit technique can be raised: It is rather slow, since it involves a fairly long search; if best-fit is not substantially better than first-fit for other reasons, this extra searching time is not worthwhile. More importantly, the best-fit method tends to increase the number of very small blocks, and proliferation of small blocks is usually undesirable. There are certain situations in which the first-fit technique is demonstrably better than the best-fit method; for example, suppose we are given just two available areas of memory, of sizes 1300 and 1200, and suppose there are subsequent requests for blocks of sizes 1000, 1100, and 250:</p>

  <div class="equation"><a id="ch02eq-lev1sec5-1"></a><img src="../Images/ch02/437equ01.jpg"></div>

  <p>(A contrary example appears in <a href="../Text/ch02c.html#ch02ex_1_5_7">exercise 7</a>.) The point is that neither method clearly dominates the other, hence the simple first-fit method can be recommended.</p>

  <p><a id="ch02alg-lev1sec5-A"></a><strong>Algorithm A</strong> (<em>First-fit method</em>). Let <code>AVAIL</code> point to the first available block of storage, and suppose that each available block with address <code>P</code> has two fields: <code>SIZE(P)</code>, the number of words in the block; and <code>LINK(P)</code>, a pointer to the next available block. The last pointer is <em>Λ</em>. This algorithm searches for and reserves a block of <code>N</code> words, or reports failure.</p>

  <p class="indenthanging"><strong>A1.</strong> [Initialize.] Set <code>Q</code> ← <code>LOC(AVAIL)</code>. (Throughout the algorithm we use two pointers, <code>Q</code> and <code>P</code>, which are generally related by the condition <code>P</code> = <code>LINK(Q)</code>. We assume that <code>LINK(LOC(AVAIL))</code> = <code>AVAIL</code>.)</p>

  <p class="indenthanging"><strong>A2.</strong> [End of list?] Set <code>P</code> ← <code>LINK(Q)</code>. If <code>P</code> = <em>Λ</em>, the algorithm terminates unsuccessfully; there is no room for a block of <code>N</code> consecutive words.</p>

  <p class="indenthanging"><strong>A3.</strong> [Is <code>SIZE</code> enough?] If <code>SIZE(P)</code> ≥ <code>N</code>, go to A4; otherwise set <code>Q</code> ← <code>P</code> and return to step A2.</p>

  <p class="indenthanging"><strong>A4.</strong> [Reserve <code>N</code>.] Set <code>K</code> ← <code>SIZE(P)</code> − <code>N</code>. If <code>K</code> = 0, set <code>LINK(Q)</code> ← <code>LINK(P)</code> (thereby removing an empty area from the list); otherwise set <code>SIZE(P)</code> ← <code>K</code>. The algorithm terminates successfully, having reserved an area of length <code>N</code> beginning with location <code>P</code> + <code>K</code>. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent">This algorithm is certainly straightforward enough. However, a significant improvement in its running speed can be made with only a rather slight change in strategy. This improvement is quite important, and the reader will find it a pleasure to discover it without being told the secret (see <a href="../Text/ch02c.html#ch02ex_1_5_6">exercise 6</a>).</p>

  <p class="indent"><a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> may be used whether storage allocation is desired for small <code>N</code> or large <code>N</code>. Let us assume temporarily, however, that we are primarily interested in <em>large</em> values of <code>N</code>. Then notice what happens when <code>SIZE(P)</code> is equal to <code>N</code>+1 in that algorithm: We get to step A4 and reduce <code>SIZE(P)</code> to 1. In other words, an <a id="page_438"></a>available block of size 1 has just been created; this block is so small it is virtually useless, and it just clogs up the system. We would have been better off if we had reserved the whole block of <code>N</code> + 1 words, instead of saving the extra word; it is often better to expend a few words of memory to avoid handling unimportant details. Similar remarks apply to blocks of <code>N</code> + <code>K</code> words when <code>K</code> is very small.</p>

  <p class="indent">If we allow the possibility of reserving slightly more than <code>N</code> words it will be necessary to remember how many words have been reserved, so that later when this block becomes available again the entire set of <code>N</code> + <code>K</code> words is freed. This added amount of bookkeeping means that we are tying up space in <em>every</em> block in order to make the system more efficient only in certain circumstances when a tight fit is found; so the strategy doesn’t seem especially attractive. However, a special <em>control word</em> as the first word of each variable-size block often turns out to be desirable for other reasons, and so it is usually not unreasonable to expect the <code>SIZE</code> field to be present in the first word of all blocks, whether they are available or reserved.</p>

  <p class="indent">In accordance with these conventions, we would modify step A4 above to read as follows:</p>

  <p class="indenthangingA"><strong>A4</strong>′<strong>.</strong> [Reserve ≥ <code>N</code>.] Set <code>K</code> ← <code>SIZE(P)</code> − <code>N</code>. If <code>K</code> &lt; <em>c</em> (where <em>c</em> is a small positive constant chosen to reflect an amount of storage we are willing to sacrifice in the interests of saving time), set <code>LINK(Q)</code> ← <code>LINK(P)</code> and <code>L</code> ← <code>P</code>. Otherwise set <code>SIZE(P)</code> ← <code>K</code>, <code>L</code> ← <code>P</code> + <code>K</code>, <code>SIZE(L)</code> ← <code>N</code>. The algorithm terminates successfully, having reserved an area of length <code>N</code> or more beginning with location <code>L</code>.</p>

  <p class="indent">A value for the constant <em>c</em> of about 8 or 10 is suggested, although very little theory or empirical evidence exists to compare this with other choices. When the best-fit method is being used, the test of <code>K</code> &lt; <em>c</em> is even <em>more</em> important than it is for the first-fit method, because tighter fits (smaller values of <code>K</code>) are much more likely to occur, and the number of available blocks should be kept as small as possible for that algorithm.</p>

  <p><strong>B. Liberation.</strong> Now let’s consider the inverse problem: How should we return blocks to the available space list when they are no longer needed?</p>

  <p class="indent">It is perhaps tempting to dismiss this problem by using garbage collection (see <a href="../Text/ch02c.html#ch02lev2sec11">Section 2.3.5</a>); we could follow a policy of simply doing nothing until space runs out, then searching for all the areas currently in use and fashioning a new <code>AVAIL</code> list.</p>

  <p class="indent">The idea of garbage collection is not to be recommended, however, for all applications. In the first place, we need a fairly “disciplined” use of pointers if we are to be able to guarantee that all areas currently in use will be easy to locate, and this amount of discipline is often lacking in the applications considered here. Secondly, as we have seen before, garbage collection tends to be slow when the memory is nearly full.</p>

  <p class="indent">There is another more important reason why garbage collection is not satisfactory, due to a phenomenon that did not confront us in our previous discussion of the technique: Suppose that there are two adjacent areas of memory, both <a id="page_439"></a>of which are available, but because of the garbage-collection philosophy one of them (shown shaded) is not in the <code>AVAIL</code> list.</p>

  <div class="equation"><a id="ch02eq-lev1sec5-2"></a><img src="../Images/ch02/439equ01.jpg"></div>

  <p>In this diagram, the heavily shaded areas at the extreme left and right are unavailable. We may now reserve a section of the area known to be available:</p>

  <div class="equation"><a id="ch02eq-lev1sec5-3"></a><img src="../Images/ch02/439equ02.jpg"></div>

  <p>If garbage collection occurs at this point, we have two separate free areas,</p>

  <div class="equation"><a id="ch02eq-lev1sec5-4"></a><img src="../Images/ch02/439equ03.jpg"></div>

  <p>Boundaries between available and reserved areas have a tendency to perpetuate themselves, and as time goes on the situation gets progressively worse. But if we had used a philosophy of returning blocks to the <code>AVAIL</code> list as soon as they become free, <em>and collapsing adjacent available areas together</em>, we would have collapsed (<a href="../Text/ch02c.html#ch02eq-lev1sec5-2">2</a>) into</p>

  <div class="equation"><a id="ch02eq-lev1sec5-5"></a><img src="../Images/ch02/439equ04.jpg"></div>

  <p>and we would have obtained</p>

  <div class="equation"><a id="ch02eq-lev1sec5-6"></a><img src="../Images/ch02/439equ05.jpg"></div>

  <p>which is much better than (<a href="../Text/ch02c.html#ch02eq-lev1sec5-4">4</a>). This phenomenon causes the garbage-collection technique to leave memory more broken up than it should be.</p>

  <p class="indent">In order to remove this difficulty, we can use garbage collection together with the process of <em>compacting memory</em>, that is, moving all the reserved blocks into consecutive locations, so that all available blocks come together whenever garbage collection is done. The allocation algorithm now becomes completely trivial by contrast with <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a>, since there is only one available block at all times. Even though this technique takes time to recopy all the locations that are in use, and to change the value of the link fields therein, it can be applied with reasonable efficiency when there is a disciplined use of pointers, and when there is a spare link field in each block for use by the garbage collection algorithms. (See <a href="../Text/ch02c.html#ch02ex_1_5_33">exercise 33</a>.)</p>

  <p class="indent">Since many applications do not meet the requirements for the feasibility of garbage collection, we shall now study methods for returning blocks of memory to the available space list. The only difficulty in these methods is the collapsing problem: Two adjacent free areas should be merged into one. In fact, when an area bounded by two available blocks becomes free, all three areas should be merged together into one. <em>In this way a good balance is obtained in memory even though storage areas are continually reserved and freed over a long period of time</em>. (For a proof of this fact, see the “fifty-percent rule” below.)</p>

  <p class="indent">The problem is to determine whether the areas at either side of the returned block are currently available; and if they are, we want to update the <code>AVAIL</code> list properly. The latter operation is a little more difficult than it sounds.</p>

  <p class="indent"><a id="page_440"></a>The first solution to these problems is to maintain the <code>AVAIL</code> list in order of increasing memory locations.</p>

  <p><a id="ch02alg-lev1sec5-B"></a><strong>Algorithm B</strong> (<em>Liberation with sorted list</em>). Under the assumptions of <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a>, with the additional assumption that the <code>AVAIL</code> list is sorted by memory location (that is, if <code>P</code> points to an available block and <code>LINK(P)</code> ≠ <em>Λ</em>, then <code>LINK(P)</code> &gt; <code>P</code>), this algorithm adds the block of <code>N</code> consecutive cells beginning at location <code>P0</code> to the <code>AVAIL</code> list. We naturally assume that none of these <code>N</code> cells is already available.</p>

  <p class="indenthanging"><strong>B1.</strong> [Initialize.] Set <code>Q</code> ← <code>LOC(AVAIL)</code>. (See the remarks in step A1 above.)</p>

  <p class="indenthanging"><strong>B2.</strong> [Advance <code>P</code>.] Set <code>P</code> ← <code>LINK(Q)</code>. If <code>P</code> = Λ, or if <code>P</code> &gt; <code>P0</code>, go to B3; otherwise set <code>Q</code> ← <code>P</code> and repeat step B2.</p>

  <p class="indenthanging"><strong>B3.</strong> [Check upper bound.] If <code>P0</code> + <code>N</code> = <code>P</code> and <code>P</code> ≠ <em>Λ</em>, set <code>N</code> ← <code>N</code> + <code>SIZE(P)</code> and set <code>LINK(P0)</code> ← <code>LINK(P)</code>. Otherwise set <code>LINK(P0)</code> ← <code>P</code>.</p>

  <p class="indenthanging"><strong>B4.</strong> [Check lower bound.] If <code>Q</code> + <code>SIZE(Q)</code> = <code>P0</code> (we assume that</p>

  <p class="center"><code>SIZE(LOC(AVAIL))</code> = 0,</p>

  <p class="indenthangingAP">so this test always fails when <code>Q</code> = <code>LOC(AVAIL)</code>), set <code>SIZE(Q)</code> ← <code>SIZE(Q)</code> + <code>N</code> and <code>LINK(Q)</code> ← <code>LINK(P0)</code>. Otherwise set <code>LINK(Q)</code> ← <code>P0</code>, <code>SIZE(P0)</code> ← <code>N</code>. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p>Steps B3 and B4 do the desired collapsing, based on the fact that the pointers <code>Q</code> &lt; <code>P0</code> &lt; <code>P</code> are the beginning locations of three consecutive available areas.</p>

  <p class="indent">If the <code>AVAIL</code> list is not maintained in order of locations, the reader can see that a “brute force” approach to the collapsing problem would require a complete search through the entire <code>AVAIL</code> list; <a href="../Text/ch02c.html#ch02alg-lev1sec5-B">Algorithm B</a> reduces this to a search through about <em>half</em> of the <code>AVAIL</code> list (in step B2) on the average. <a href="../Text/ch02c.html#ch02ex_1_5_11">Exercise 11</a> shows how <a href="../Text/ch02c.html#ch02alg-lev1sec5-B">Algorithm B</a> can be modified so that, on the average, only about one-third of the <code>AVAIL</code> list must be searched. But obviously, when the <code>AVAIL</code> list is long, all of these methods are much slower than we want them to be. Isn’t there some way to reserve and free storage areas so that we don’t need to do extensive searching through the <code>AVAIL</code> list?</p>

  <p class="indent">We will now consider a method that eliminates all searching when storage is returned and that can be modified, as in <a href="../Text/ch02c.html#ch02ex_1_5_6">exercise 6</a>, to avoid almost all of the searching when storage is reserved. The technique makes use of a <code>TAG</code> field at both ends of each block, and a <code>SIZE</code> field in the first word of each block; this overhead is negligible when reasonably large blocks are being used, although it is perhaps too much of a penalty to pay in situations when the blocks have a very small average size. Another method described in <a href="../Text/ch02c.html#ch02ex_1_5_19">exercise 19</a> requires only one bit in the first word of each block, at the expense of a little more running time and a slightly more complicated program.</p>

  <p class="indent">At any rate, let us now assume that we don’t mind adding a little bit of control information, in order to save a good deal of time over <a href="../Text/ch02c.html#ch02alg-lev1sec5-B">Algorithm B</a> when the <code>AVAIL</code> list is long. The method we will describe assumes that each block has <a id="page_441"></a>the following form:</p>

  <div class="equation"><a id="ch02eq-lev1sec5-7"></a><img src="../Images/ch02/441equ01.jpg"></div>

  <p class="indent">The idea in the following algorithm is to maintain a doubly linked <code>AVAIL</code> list, so that entries may conveniently be deleted from random parts of the list. The <code>TAG</code> field at either end of a block can be used to control the collapsing process, since we can tell easily whether or not both adjacent blocks are available.</p>

  <p class="indent">Double linking is achieved in a familiar way, by letting the <code>LINK</code> in the first word point to the next free block in the list, and letting the <code>LINK</code> in the second word point back to the previous block; thus, if <code>P</code> is the address of an available block, we always have</p>

  <div class="equation"><a id="ch02eq-lev1sec5-8"></a><img src="../Images/ch02/441equ02.jpg"></div>

  <p>To ensure proper “boundary conditions,” the list head is set up as follows:</p>

  <div class="equation"><a id="ch02eq-lev1sec5-9"></a><img src="../Images/ch02/441equ03.jpg"></div>

  <p class="indent">A first-fit reservation algorithm for this technique may be designed very much like <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a>, so we shall not consider it here (see <a href="../Text/ch02c.html#ch02ex_1_5_12">exercise 12</a>). The principal new feature of this method is the way the block can be freed in essentially a fixed amount of time:</p>

  <p><a id="ch02alg-lev1sec5-C"></a><strong>Algorithm C</strong> (<em>Liberation with boundary tags</em>). Assume that blocks of locations have the forms shown in (<a href="../Text/ch02c.html#ch02eq-lev1sec5-7">7</a>), and assume that the <code>AVAIL</code> list is doubly linked, as described above. This algorithm puts the block of locations starting with address <code>P0</code> into the <code>AVAIL</code> list. If the pool of available storage runs from locations <em>m</em><sub>0</sub> through <em>m</em><sub>1</sub>, inclusive, the algorithm assumes for convenience that</p>

  <p class="center"><code>TAG(</code><em>m</em><sub>0</sub> − 1<code>)</code> = <code>TAG(</code><em>m</em><sub>1</sub> + 1<code>)</code> = “+”.</p>

  <p class="indenthanging"><strong>C1.</strong> [Check lower bound.] If <code>TAG(P0</code> − 1<code>)</code> = “+”, go to C3.</p>

  <p class="indenthanging"><strong>C2.</strong> [Delete lower area.] Set <code>P</code> ← <code>P0</code>−<code>SIZE(P0</code> − 1<code>)</code>, and then set <code>P1</code> ← <code>LINK(P)</code>, <code>P2</code> ← <code>LINK(P</code> + 1<code>)</code>, <code>LINK(P1</code> + 1<code>)</code> ← <code>P2</code>, <code>LINK(P2)</code> ← <code>P1</code>, <code>SIZE(P)</code> ← <code>SIZE(P)</code> + <code>SIZE(P0)</code>, <code>P0</code> ← <code>P</code>.</p>

  <p class="indenthanging"><strong>C3.</strong> [Check upper bound.] Set <code>P</code> ← <code>P0</code> + <code>SIZE(P0)</code>. If <code>TAG(P)</code> = “+”, go to C5.</p>

  <p class="indenthanging"><strong>C4.</strong> [Delete upper area.] Set <code>P1</code> ← <code>LINK(P)</code>, <code>P2</code> ← <code>LINK(P</code>+1<code>)</code>, <code>LINK(P1</code>+1<code>)</code> ← <code>P2</code>, <code>LINK(P2)</code> ← <code>P1</code>, <code>SIZE(P0)</code> ← <code>SIZE(P0)</code> + <code>SIZE(P)</code>, <code>P</code> ← <code>P</code> + <code>SIZE(P)</code>.</p>

  <p class="indenthanging"><a id="page_442"></a><strong>C5.</strong> [Add to <code>AVAIL</code> list.] Set <code>SIZE(P</code> − 1<code>)</code> ← <code>SIZE(P0)</code>, <code>LINK(P0)</code> ← <code>AVAIL</code>, <code>LINK(P0</code> + 1<code>)</code> ← <code>LOC(AVAIL)</code>, <code>LINK(AVAIL</code> + 1<code>)</code> ← <code>P0</code>, <code>AVAIL</code> ← <code>P0</code>, <code>TAG(P0)</code> ← <code>TAG(P</code> − 1<code>)</code> ← “−”. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p class="indent">The steps of <a href="../Text/ch02c.html#ch02alg-lev1sec5-C">Algorithm C</a> are straightforward consequences of the storage layout (<a href="../Text/ch02c.html#ch02eq-lev1sec5-7">7</a>); a slightly longer algorithm that is a little faster appears in <a href="../Text/ch02c.html#ch02ex_1_5_15">exercise 15</a>. In step C5, <code>AVAIL</code> is an abbreviation for <code>LINK(LOC(AVAIL))</code>, as shown in (<a href="../Text/ch02c.html#ch02eq-lev1sec5-9">9</a>).</p>

  <p><strong>C. The “buddy system.”</strong> We will now study another approach to dynamic storage allocation, suitable for use with binary computers. This method uses one bit of overhead in each block, and it requires all blocks to be of length 1, 2, 4, 8, or 16, etc. If a block is not 2<em><sup>k</sup></em> words long for some integer <em>k</em>, the next higher power of 2 is chosen and extra unused space is allocated accordingly.</p>

  <p class="indent">The idea of this method is to keep separate lists of available blocks of each size 2<em><sup>k</sup></em>, 0 <em>≤ k ≤ m</em>. The entire pool of memory space under allocation consists of 2<em><sup>m</sup></em> words, which can be assumed to have the addresses 0 through 2<em><sup>m</sup></em> − 1. Originally, the entire block of 2<em><sup>m</sup></em> words is available. Later, when a block of <em>2k</em> words is desired, and if nothing of this size is available, a larger available block is <em>split</em> into two equal parts; ultimately, a block of the right size 2<em><sup>k</sup></em> will appear. When one block splits into two (each of which is half as large as the original), these two blocks are called <em>buddies</em>. Later when both buddies are available again, they coalesce back into a single block; thus the process can be maintained indefinitely, unless we run out of space at some point.</p>

  <p class="indent">The key fact underlying the practical usefulness of this method is that if we know the address of a block (the memory location of its first word), and if we also know the size of that block, we know the address of its buddy. For example, the buddy of the block of size 16 beginning in binary location 101110010110000 is a block starting in binary location 101110010100000. To see why this must be true, we first observe that as the algorithm proceeds, <em>the address of a block of size</em> 2<em><sup>k</sup> is a multiple of</em> 2<em><sup>k</sup></em>. In other words, the address in binary notation has at least <em>k</em> zeros at the right. This observation is easily justified by induction: If it is true for all blocks of size 2<sup><em>k</em>+1</sup>, it is certainly true when such a block is halved.</p>

  <p class="indent">Therefore a block of size, say, 32 has an address of the form <em>xx... x</em>00000 (where the <em>x</em>’s represent either 0 or 1); if it is split, the newly formed buddy blocks have the addresses <em>xx... x</em>00000 and <em>xx... x</em>10000. In general, let buddy<em><sub>k</sub></em>(<em>x</em>) = address of the buddy of the block of size 2<em><sup>k</sup></em> whose address is <em>x</em>; we find that</p>

  <div class="equation"><a id="ch02eq-lev1sec5-10"></a><img src="../Images/ch02/442equ01.jpg"></div>

  <p>This function is readily computed with the “exclusive or” instruction (sometimes called “selective complement” or “add without carry”) usually found on binary computers; see <a href="../Text/ch02c.html#ch02ex_1_5_28">exercise 28</a>.</p>

  <p class="indent">The buddy system makes use of a one-bit <code>TAG</code> field in each block:</p>

  <div class="equation"><a id="ch02eq-lev1sec5-11"></a><img src="../Images/ch02/442equ02.jpg"></div>

  <p><a id="page_443"></a>This <code>TAG</code> field is present in all blocks, and it must not be tampered with by the users who reserve blocks. The <em>available</em> blocks also have two link fields, <code>LINKF</code> and <code>LINKB</code>, which are the usual forward and backward links of a doubly linked list; and they also have a <code>KVAL</code> field to specify <em>k</em> when their size is 2<em><sup>k</sup></em>. The algorithms below make use of the table locations <code>AVAIL[</code>0<code>]</code>, <code>AVAIL[</code>1<code>]</code>, <em>...</em>, <code>AVAIL[</code><em>m</em><code>]</code>, which serve respectively as the heads of the lists of available storage of sizes 1, 2, 4, <em>...</em>, 2<em><sup>m</sup></em>. These lists are doubly linked, so as usual the list heads contain two pointers (see <a href="../Text/ch02.html#ch02lev2sec5">Section 2.2.5</a>):</p>

  <div class="equation"><a id="ch02eq-lev1sec5-12"></a><img src="../Images/ch02/443equ01.jpg"></div>

  <p>Initially, before any storage has been allocated, we have</p>

  <div class="equation"><a id="ch02eq-lev1sec5-13"></a><img src="../Images/ch02/443equ02.jpg"></div>

  <p>(indicating a single available block of length 2<em><sup>m</sup></em>, beginning in location 0), and</p>

  <div class="equation"><a id="ch02eq-lev1sec5-14"></a><img src="../Images/ch02/443equ03.jpg"></div>

  <p>(indicating empty lists for available blocks of lengths 2<em><sup>k</sup></em> for all <em>k &lt; m</em>).</p>

  <p class="indent">From this description of the buddy system, the reader may find it enjoyable to design the necessary algorithms for reserving and freeing storage areas before looking at the algorithms given below. Notice the comparative ease with which blocks can be halved in the reservation algorithm.</p>

  <p><a id="ch02alg-lev1sec5-R"></a><strong>Algorithm R</strong> (<em>Buddy system reservation</em>). This algorithm finds and reserves a block of 2<em><sup>k</sup></em> locations, or reports failure, using the organization of the buddy system as explained above.</p>

  <p class="indenthanging"><strong>R1.</strong> [Find block.] Let <em>j</em> be the smallest integer in the range <em>k ≤ j ≤ m</em> for which <code>AVAILF[</code><em>j</em><code>]</code> ≠ <code>LOC(AVAIL[</code><em>j</em><code>])</code>, that is, for which the list of available blocks of size 2<em><sup>j</sup></em> is not empty. If no such <em>j</em> exists, the algorithm terminates unsuccessfully, since there are no known available blocks of sufficient size to meet the request.</p>

  <p class="indenthanging"><strong>R2.</strong> [Remove from list.] Set <code>L</code> ← <code>AVAILB[</code><em>j</em><code>]</code>, <code>P</code> ← <code>LINKB(L)</code>, <code>AVAILB[</code><em>j</em><code>]</code> ← <code>P</code>, <code>LINKF(P)</code> ← <code>LOC(AVAIL[</code><em>j</em><code>])</code>, and <code>TAG(L)</code> ← 0.</p>

  <p class="indenthanging"><strong>R3.</strong> [Split required?] If <em>j</em> = <em>k</em>, the algorithm terminates (we have found and reserved an available block starting at address <code>L</code>).</p>

  <p class="indenthanging"><strong>R4.</strong> [Split.] Decrease <em>j</em> by 1. Then set <code>P</code> ← <code>L</code> + 2<em><sup>j</sup></em>, <code>TAG(P)</code> ← 1, <code>KVAL(P)</code> <em>← j</em>, <code>LINKF(P)</code> ← <code>LINKB(P)</code> ← <code>LOC(AVAIL[</code><em>j</em><code>])</code><em>,</em> <code>AVAILF[</code><em>j</em><code>]</code> ← <code>AVAILB[</code><em>j</em><code>]</code> ← <code>P</code>. (This splits a large block and enters the unused half in the <code>AVAIL[</code><em>j</em><code>]</code> list, which was empty.) Go back to step R3. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p><a id="ch02alg-lev1sec5-S"></a><strong>Algorithm S</strong> (<em>Buddy system liberation</em>). This algorithm returns a block of 2<em><sup>k</sup></em> locations, starting in address <code>L</code>, to free storage, using the organization of the buddy system as explained above.</p>

  <p class="indenthanging"><a id="page_444"></a><strong>S1.</strong> [Is buddy available?] Set <code>P</code> ← buddy<em><sub>k</sub></em><code>(L)</code>. (See Eq. (<a href="../Text/ch02c.html#ch02eq-lev1sec5-10">10</a>).) If <em>k</em> = <em>m</em> or if <code>TAG(P)</code> = 0, or if <code>TAG(P)</code> = 1 and <code>KVAL(P)</code> ≠ <em>k</em>, go to S3.</p>

  <p class="indenthanging"><strong>S2.</strong> [Combine with buddy.] Set</p>

  <p class="center"><code>LINKF(LINKB(P))</code> ← <code>LINKF(P)</code><em>,</em>&nbsp;&nbsp;&nbsp;<code>LINKB(LINKF(P))</code> ← <code>LINKB(P)</code>.</p>

  <p class="indenthangingAP">(This removes block <code>P</code> from the <code>AVAIL[</code><em>k</em><code>]</code> list.) Then set <em>k ← k</em> + 1, and if <code>P</code> &lt; <code>L</code> set <code>L</code> ← <code>P</code>. Return to S1.</p>

  <p class="indenthanging"><strong>S3.</strong> [Put on list.] Set <code>TAG(L)</code> ← 1, <code>P</code> ← <code>AVAILF[</code><em>k</em><code>]</code>, <code>LINKF(L)</code> ← <code>P</code>, <code>LINKB(P)</code> ← <code>L</code><em>,</em> <code>KVAL(L)</code> <em>← k</em>, <code>LINKB(L)</code> ← <code>LOC(AVAIL[</code><em>k</em><code>])</code>, <code>AVAILF[</code><em>k</em><code>]</code> ← <code>L</code>. (This puts block <code>L</code> on the <code>AVAIL[</code><em>k</em><code>]</code> list.) <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p><strong>D. Comparison of the methods.</strong> The mathematical analysis of these dynamic storage-allocation algorithms has proved to be quite difficult, but there is one interesting phenomenon that is fairly easy to analyze, namely the “fifty-percent rule”:</p>

  <p class="uln-indent"><em>If <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">B</a> are used continually in such a way that the system tends to an equilibrium condition, where there are N reserved blocks in the system, on the average, each equally likely to be the next one freed, and where the quantity</em> <code>K</code> <em>in <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> takes on nonzero values (or, more generally, values ≥ c as in step A4′) with probability p, then the average number of available blocks tends to approximately</em> <span class="middle"><img src="../Images/ch02/1by2.jpg"></span> <em>pN.</em></p>

  <p>This rule tells us approximately how long the <code>AVAIL</code> list will be. When the quantity <em>p</em> is near 1 — this will happen if <em>c</em> is very small and if the block sizes are infrequently equal to each other — we have about half as many available blocks as unavailable ones; hence the name “fifty-percent rule.”</p>

  <p class="indent">It is not hard to derive this rule. Consider the following memory map:</p>

  <div class="image"><img src="../Images/ch02/e444_01.jpg"></div>

  <p>This shows the reserved blocks divided into three categories:</p>

  <p class="indenthangingA"><em>A</em>: when freed, the number of available blocks will decrease by one;</p>

  <p class="indenthangingA"><em>B</em>: when freed, the number of available blocks will not change;</p>

  <p class="indenthangingA"><em>C</em>: when freed, the number of available blocks will increase by one.</p>

  <p>Now let <em>N</em> be the number of reserved blocks, and let <em>M</em> be the number of available ones; let <em>A</em>, <em>B</em>, and <em>C</em> be the number of blocks of the types identified above. We have</p>

  <div class="equation"><a id="ch02eq-lev1sec5-15"></a><img src="../Images/ch02/444equ01.jpg"></div>

  <p>where <span class="ent">∊</span> = 0, 1, or 2 depending on conditions at the lower and upper boundaries.</p>

  <p class="indent">Let us assume that <em>N</em> is essentially constant, but that <em>A</em>, <em>B</em>, <em>C</em>, and <span class="ent">∊</span> are random quantities that reach a stationary distribution after a block is freed and a (slightly different) stationary distribution after a block is allocated. The average change in <em>M</em> when a block is freed is the average value of (<em>C −A</em>)<em>/N</em>; the average change in <em>M</em> when a block is allocated is −1 + <em>p</em>. So the equilibrium assumption <a id="page_445"></a>tells us that the average value of <em>C − A − N</em> + <em>pN</em> is zero. But then the average value of 2<em>M</em> is <em>pN</em> plus the average value of <span class="ent">∊</span>, since 2<em>M</em> = <em>N</em> + <em>A − C</em> + <span class="ent">∊</span> by (<a href="../Text/ch02c.html#ch02eq-lev1sec5-15">15</a>). The fifty-percent rule follows.</p>

  <p class="indent">Our assumption that each deletion applies to a random reserved block will be valid if the lifetime of a block is an exponentially distributed random variable. On the other hand, if all blocks have roughly the same lifetime, this assumption is false; John E. Shore has pointed out that type A blocks tend to be “older” than type C blocks when allocations and liberations tend to have a somewhat first-in-first-out character, since a sequence of adjacent reserved blocks tends to be in order from youngest to oldest and since the most recently allocated block is almost never type A. This tends to produce a smaller number of available blocks, giving even better performance than the fifty-percent rule would predict. [See <em>CACM</em> <strong>20</strong> (1977), 812–820.]</p>

  <p class="indent">For more detailed information about the fifty-percent rule, see D. J. M. Davies, <em>BIT</em> <strong>20</strong> (1980), 279–288; C. M. Reeves, <em>Comp. J.</em> <strong>26</strong> (1983), 25–35; G. Ch. Pflug, <em>Comp. J.</em> <strong>27</strong> (1984), 328–333.</p>

  <p class="indent">Besides this interesting rule, our knowledge of the performance of dynamic storage allocation algorithms is based almost entirely on Monte Carlo experiments. Readers will find it instructive to conduct their own simulation experiments when they are choosing between storage allocation algorithms for a particular machine and a particular application or class of applications. The author carried out several such experiments just before writing this section (and, indeed, the fifty-percent rule was noticed during those experiments before a proof for it was found); let us briefly examine the methods and results of those experiments here.</p>

  <p class="indent">The basic simulation program ran as follows, with <code>TIME</code> initially zero and with the memory area initially all available:</p>

  <p class="indenthanging"><strong>P1.</strong> [Tick.] Advance <code>TIME</code> by 1.</p>

  <p class="indenthanging"><strong>P2.</strong> [Sync.] Free all blocks in the system that are scheduled to be freed at the current value of <code>TIME</code>.</p>

  <p class="indenthanging"><strong>P3.</strong> [Get data.] Calculate two quantities <em>S</em> (a random size) and <em>T</em> (a random lifetime), based on some probability distributions, using the methods of Chapter 3.</p>

  <p class="indenthanging"><strong>P4.</strong> [Use data.] Reserve a new block of length <em>S</em>, which is due to be freed at (<code>TIME</code> + <em>T</em>). Return to P1. <span class="middle"><img src="../Images/ch02/common-01.jpg"></span></p>

  <p>Whenever <code>TIME</code> was a multiple of 200, detailed statistics about the performance of the reservation and liberation algorithms were printed. The same sequence of values of <em>S</em> and <em>T</em> was used for each pair of algorithms tested. After <code>TIME</code> advanced past 2000, the system usually had reached a more or less steady state that gave every indication of being maintained indefinitely thereafter. However, depending on the total amount of storage available and on the distributions of <em>S</em> and <em>T</em> in step P3, the allocation algorithms would occasionally fail to find enough space and the simulation experiment was then terminated.</p>

  <p class="indent"><a id="page_446"></a>Let <em>C</em> be the total number of memory locations available, and let <span class="middle"><img src="../Images/ch02/s-bar.jpg"></span> and <span class="middle"><img src="../Images/ch02/t-bar.jpg"></span> denote the average values of <em>S</em> and <em>T</em> in step P3. It is easy to see that the expected number of unavailable words of memory at any given time is <span class="middle"><img src="../Images/ch02/st-bar.jpg"></span>, once <code>TIME</code> is sufficiently large. When <span class="middle"><img src="../Images/ch02/st-bar.jpg"></span> was greater than about <span class="middle"><img src="../Images/ch02/e446_01.jpg"></span> in the experiments, memory overflow usually occurred, often before <em>C</em> words of memory were actually needed. The memory was able to become over 90 percent filled when the block size was small compared to <em>C</em>, but when the block sizes were allowed to exceed <span class="middle"><img src="../Images/ch02/e446_02.jpg"></span> (as well as taking on much smaller values) the program tended to regard the memory as “full” when fewer than <span class="middle"><img src="../Images/ch02/e446_03.jpg"></span> locations were actually in use. Empirical evidence suggests strongly that <em>block sizes larger than</em> <span class="middle"><img src="../Images/ch02/e446_04.jpg"></span> <em>should not be used with dynamic storage allocation</em> if effective operation is expected.</p>

  <p class="indent">The reason for this behavior can be understood in terms of the fifty-percent rule: If the system reaches an equilibrium condition in which the size <em>f</em> of an average free block is less than the size <em>r</em> of an average block in use, we can expect to get an unfillable request unless a large free block is available for emergencies. Hence <em>f ≥ r</em> in a saturated system that doesn’t overflow, and we have <em>C</em> = <em>fM</em> + <em>rN ≥ rM</em> + <em>rN</em> ≈ (<em>p/</em>2 + 1)<em>rN</em>. The total memory in use is therefore <em>rN ≤ C/</em>(<em>p/</em>2 + 1); when <em>p</em> ≈ 1 we are unable to use more than about 2<em>/</em>3 of the memory cells.</p>

  <p class="indent">The experiments were conducted with three size distributions for <em>S</em>:</p>

  <p class="uln-indent">(<em>S1</em>) an integer chosen uniformly between 100 and 2000;</p>

  <p class="uln-indent">(<em>S2</em>) sizes (1, 2, 4, 8, 16, 32) chosen with respective probabilities (<span class="middle"><img src="../Images/ch02/e446_05.jpg"></span>);</p>

  <p class="uln-indent">(<em>S3</em>) sizes (10, 12, 14, 16, 18, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 500, 1000, 2000, 3000, 4000) selected with equal probability.</p>

  <p>The time distribution <em>T</em> was usually a random integer chosen uniformly between 1 and <em>t</em>, for fixed <em>t</em> = 10, 100, or 1000.</p>

  <p class="indent">Experiments were also made in which <em>T</em> was chosen uniformly between 1 and min (<span class="middle"><img src="../Images/ch02/e446_06.jpg"></span>) in step P3, where <em>U</em> is the number of time units remaining the next scheduled freeing of some currently reserved block in the system. This time distribution was meant to simulate an “almost-last-in-first-out” behavior: For if <em>T</em> were always chosen <em>≤ U</em>, the storage allocation system would degenerate into simply a stack operation requiring no complex algorithms. (See <a href="../Text/ch02c.html#ch02ex_1_5_1">exercise 1</a>.) The stated distribution causes <em>T</em> to be chosen greater than <em>U</em> about 20 percent of the time, so we have almost, but not quite, a stack operation. When this distribution was used, algorithms such as A, B, and C behaved much better than usual; there were rarely, if ever, more than two items in the entire <code>AVAIL</code> list, while there were about 14 reserved blocks. On the other hand, the buddy system algorithms, R and S, were slower when this distribution was used, because they tend to split and coalesce blocks more frequently in a stack-like operation. The theoretical properties of this time distribution appear to be quite difficult to deduce (see <a href="../Text/ch02c.html#ch02ex_1_5_32">exercise 32</a>).</p>

  <p class="indent"><a href="../Text/ch02c.html#ch02fig42">Figure 42</a>, which appeared near the beginning of this section, was the configuration of memory at <code>TIME</code> = 5000, with size distribution (<em>S1</em>) and with the <a id="page_447"></a>times distributed uniformly in \{1<em>, ...,</em> 100\}, using the first-fit method just as in <a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">B</a> above. For this experiment, the probability <em>p</em> that enters into the “fifty-percent rule” was essentially 1, so we would expect about half as many available blocks as reserved blocks. Actually <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a> shows 21 available and 53 reserved. This does not disprove the fifty-percent rule: For example, at <code>TIME</code> = 4600 there were 25 available and 49 reserved. The configuration in <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a> merely shows how the fifty-percent rule is subject to statistical variations. The number of available blocks generally ranged between 20 and 30, while the number of reserved blocks was generally between 45 and 55.</p>

  <p class="indent"><a href="../Text/ch02c.html#ch02fig43">Figure 43</a> shows the configuration of memory obtained with <em>the same data as <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a></em> but with the best-fit method used instead of the first-fit method. The constant <em>c</em> in step A4′ was set to 16, to eliminate small blocks, and as a result the probability <em>p</em> dropped to about 0.7 and there were fewer available areas.</p>

  <div class="image">
    <a id="ch02fig43"></a><img src="../Images/ch02/02fig43.jpg">

    <p class="fig-caption"><strong>Fig. 43.</strong> Memory map obtained with the best-fit method. (Compare this with <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a>, which shows the first-fit method, and <a href="../Text/ch02c.html#ch02fig44">Fig. 44</a>, which shows the buddy system, for the same sequence of storage requests.)</p>
  </div>

  <p class="indent">When the time distribution was changed to vary from 1 to 1000 instead of 1 to 100, situations precisely analogous to those shown in <a href="../Text/ch02c.html#ch02fig42">Figs. 42</a> and <a href="../Text/ch02c.html#ch02fig43">43</a> were obtained, with all appropriate quantities approximately multiplied by 10. For example, there were 515 reserved blocks; and 240 free blocks in the equivalent of <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a>, 176 free blocks in the equivalent of <a href="../Text/ch02c.html#ch02fig43">Fig. 43</a>.</p>

  <p class="indent">In all experiments comparing the best-fit and first-fit methods, the latter always appeared to be superior. When memory size was exhausted, the first-fit method actually stayed in action longer than the best-fit method before memory overflow occurred, in most instances.</p>

  <p class="indent">The buddy system was also applied to the same data that led to <a href="../Text/ch02c.html#ch02fig42">Figs. 42</a> and <a href="../Text/ch02c.html#ch02fig43">43</a>, and <a href="../Text/ch02c.html#ch02fig44">Fig. 44</a> was the result. Here, all sizes in the range 257 to 512 were treated as 512, those between 513 and 1024 were raised to 1024, etc. On the average this means that more than four thirds as much memory was requested (see <a href="../Text/ch02c.html#ch02ex_1_5_21">exercise 21</a>); the buddy system, of course, works better on size distributions like that of (<em>S2</em>) above, instead of (<em>S1</em>). Notice that there are available blocks of sizes 2<sup>9</sup>, 2<sup>10</sup>, 2<sup>11</sup>, 2<sup>12</sup>, 2<sup>13</sup>, and 2<sup>14</sup> in <a href="../Text/ch02c.html#ch02fig44">Fig. 44</a>.</p>

  <div class="image">
    <a id="ch02fig44"></a><img src="../Images/ch02/02fig44.jpg">

    <p class="fig-caption"><strong>Fig. 44.</strong> Memory map obtained with the buddy system. (The tree structure indicates the division of certain large blocks into buddies of half the size. Squares indicate available blocks.)</p>
  </div>

  <p class="indent">Simulation of the buddy system showed that it performs much better than might be expected. It is clear that the buddy system will sometimes allow two adjacent areas of the same size to be available without merging them into one <a id="page_448"></a>(if they are not buddies); but this situation is not present in <a href="../Text/ch02c.html#ch02fig44">Fig. 44</a> and, in fact, it is rare in practice. In cases where memory overflow occurred, memory was 95 percent reserved, and this reflects a surprisingly good allocation balance. Furthermore, it was very seldom necessary to split blocks in <a href="../Text/ch02c.html#ch02alg-lev1sec5-R">Algorithm R</a>, or to merge them in <a href="../Text/ch02c.html#ch02alg-lev1sec5-S">Algorithm S</a>; the tree remained much like <a href="../Text/ch02c.html#ch02fig44">Fig. 44</a>, with available blocks on the most commonly used levels. Some mathematical results that give insight into this behavior, at the lowest level of the tree, have been obtained by P. W. Purdom, Jr., and S. M. Stigler, <em>JACM</em> <strong>17</strong> (1970), 683–697.</p>

  <p class="indent">Another surprise was the excellent behavior of <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> after the modification described in <a href="../Text/ch02c.html#ch02ex_1_5_6">exercise 6</a>; only 2.8 inspections of available block sizes were necessary on the average (using size distribution (<em>S1</em>) and times chosen uniformly between 1 and 1000), and more than half of the time only the minimum value, one iteration, was necessary. This was true in spite of the fact that about 250 available blocks were present. The same experiment with <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> unmodified showed that about 125 iterations were necessary on the average (so about half of the <code>AVAIL</code> list was being examined each time); 200 or more iterations were found to be necessary about 20 percent of the time.</p>

  <p class="indent">This behavior of <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> unmodified can, in fact, be predicted as a consequence of the fifty-percent rule. At equilibrium, the portion of memory containing the last half of the reserved blocks will also contain the last half of the free blocks; that portion will be involved half of the time when a block is freed, and so it must be involved in half of the allocations in order to maintain equilibrium. The same argument holds when one-half is replaced by any other fraction. (These observations are due to J. M. Robson.)</p>

  <p class="indent"><a id="page_449"></a>The exercises below include <code>MIX</code> programs for the two principal methods that are recommended as a consequence of the remarks above: (i) the boundary tag system, as modified in <a href="../Text/ch02c.html#ch02ex_1_5_12">exercises 12</a> and <a href="../Text/ch02c.html#ch02ex_1_5_16">16</a>; and (ii) the buddy system. Here are the approximate results:</p>

  <div class="image"><img src="../Images/ch02/e449_01.jpg"></div>

  <p>Here <em>A</em> ≥ 1 is the number of iterations necessary when searching for an available block that is large enough; <em>R</em> ≥ 0 is the number of times a block is split in two (the initial difference of <em>j − k</em> in <a href="../Text/ch02c.html#ch02alg-lev1sec5-R">Algorithm R</a>); and <em>S</em> ≥ 0 is the number of times buddy blocks are reunited during <a href="../Text/ch02c.html#ch02alg-lev1sec5-S">Algorithm S</a>. The simulation experiments indicate that under the stated assumptions with size distribution (<em>S1</em>) and time chosen between 1 and 1000, we may take <em>A</em> = 2.8, <em>R</em> = <em>S</em> = 0.04 on the average. (The average values <em>A</em> = 1.3, <em>R</em> = <em>S</em> = 0.9 were observed when the “almost-last-in-first-out” time distribution was substituted as explained above.) This shows that both methods are quite fast, with the buddy system slightly faster in <code>MIX</code>’s case. Remember that the buddy system requires about 44 percent more space when block sizes are not constrained to be powers of 2.</p>

  <p class="indent">A corresponding time estimate for the garbage collection and compacting algorithm of <a href="../Text/ch02c.html#ch02ex_1_5_33">exercise 33</a> is about 104 units of time to locate a free node, assuming that garbage collection occurs when the memory is approximately half full, and assuming that the nodes have an average length of 5 words with 2 links per node. The pros and cons of garbage collection are discussed in <a href="../Text/ch02c.html#ch02lev2sec11">Section 2.3.5</a>. When the memory is not heavily loaded and when the appropriate restrictions are met, garbage collection and compacting is very efficient; for example, on the <code>MIX</code> computer, the garbage collection method is faster than the other two, if the accessible items never occupy more than about one-third of the total memory space, and if the nodes are relatively small.</p>

  <p class="indent">If the assumptions underlying garbage collection are met, the best strategy may be to divide the pool of memory into two halves and to do all allocation sequentially within one half. Instead of freeing blocks as they become available, we simply wait until the current active half of memory is full; then we can copy all active data to the other half, simultaneously removing all holes between blocks, with a method like that of <a href="../Text/ch02c.html#ch02ex_1_5_33">exercise 33</a>. The size of each half pool might also be adjusted as we switch from one half to the other.</p>

  <p class="indent">The simulation techniques mentioned above were applied also to some other storage allocation algorithms. The other methods were so poor by comparison with the algorithms of this section that they will be given only brief mention here:</p>

  <p class="indent">a) Separate <code>AVAIL</code> lists were kept for each size. A single free block was occasionally split into two smaller blocks when necessary, but no attempt was made to put such blocks together again. The memory map became fragmented into finer and finer parts until it was in terrible shape; a simple scheme like this is almost equivalent to doing separate allocation in disjoint areas, one area for each block size.</p>

  <p class="indent"><a id="page_450"></a>b) An attempt was made to do two-level allocation: The memory was divided into 32 large sectors. A brute-force allocation method was used to reserve large blocks of 1, 2, or 3 (rarely more) adjacent sectors; each large block such as this was subdivided to meet storage requests until no more room was left within the current large block, and then another large block was reserved for use in subsequent allocations. Each large block was returned to free storage only when <em>all</em> space within it became available. This method almost always ran out of storage space very quickly.</p>

  <p class="indent">Although this particular method of two-level allocation was a failure for the data considered in the author’s simulation experiments, there are other circumstances (which occur not infrequently in practice) when a multiple-level allocation strategy can be beneficial. For example, if a rather large program operates in several stages, we might know that certain types of nodes are needed only within a certain subroutine. Some programs might also find it desirable to use quite different allocation strategies for different classes of nodes. The idea of allocating storage by zones, with possibly different strategies employed in each zone and with the ability to free an entire zone at once, is discussed by Douglas T. Ross in <em>CACM</em> <strong>10</strong> (1967), 481–492.</p>

  <p class="indent">For further empirical results about dynamic storage allocation, see the articles by B. Randell, <em>CACM</em> <strong>12</strong> (1969), 365–369, 372; P. W. Purdom, S. M. Stigler, and T. O. Cheam, <em>BIT</em> <strong>11</strong> (1971), 187–195; B. H. Margolin, R. P. Parmelee, and M. Schatzoff, <em>IBM Systems J.</em> <strong>10</strong> (1971), 283–304; J. A. Campbell, <em>Comp. J.</em> <strong>14</strong> (1971), 7–9; John E. Shore, <em>CACM</em> <strong>18</strong> (1975), 433–440; Norman R. Nielsen, <em>CACM</em> <strong>20</strong> (1977), 864–873.</p>

  <p><strong>*E. Distributed fit.</strong> If the distribution of block sizes is known in advance, and if each block present is equally likely to be the next one freed regardless of when it was allocated, we can use a technique that has substantially better memory utilization than the general-purpose techniques described so far, by following the suggestions of E. G. Coffman, Jr., and F. T. Leighton [<em>J. Computer and System Sci.</em> <strong>38</strong> (1989), 2–35]. Their “distributed-fit method” works by partitioning memory into roughly <span class="middle"><img src="../Images/ch02/e450_01.jpg"></span> slots, where <em>N</em> is the desired maximum number of blocks to be handled in steady state. Each slot has a fixed size, although different slots may have different sizes; the main point is that any given slot has fixed boundaries, and it will either be empty or contain a single allocated block.</p>

  <p class="indent">The first <em>N</em> slots in Coffman and Leighton’s scheme are laid out according to the assumed distribution of sizes, while the last <span class="middle"><img src="../Images/ch02/e450_02.jpg"></span> slots all have the maximum size. For example, if we assume that the block sizes will be uniformly distributed between 1 and 256, and if we expect to handle <em>N</em> = 2<sup>14</sup> such blocks, we would divide the memory into <em>N/</em>256 = 2<sup>6</sup> slots of each size 1, 2, <em>...</em>, 256, followed by an “overflow area” that contains <span class="middle"><img src="../Images/ch02/e450_03.jpg"></span> blocks of size 256. When the system is operating at full capacity, we expect it to handle <em>N</em> blocks of average size <span class="middle"><img src="../Images/ch02/e450_04.jpg"></span>, occupying <span class="middle"><img src="../Images/ch02/e450_05.jpg"></span> locations; this is the amount of space we have allocated to the first <em>N</em> slots. We have also <a id="page_451"></a>set aside an additional 1792 · 256 = 458<em>,</em>752 locations to handle the effects of random variations; this additional overhead amounts to <em>O</em>(<em>N</em><sup>−1<em>/</em>2</sup> log <em>N</em>) of the total space, rather than a constant multiple of <em>N</em> as in the buddy system, so it becomes a negligible fraction when <em>N</em> → ∞. In our example, however, it still amounts to about 18% of the total allocation.</p>

  <p class="indent">The slots should be arranged in order so that the smaller slots precede the larger ones. Given this arrangement, we can allocate blocks by using either the first-fit or the best-fit technique. (Both methods are equivalent in this case, because the slot sizes are ordered.) The effect, under our assumptions, is to start searching at an essentially random place among the first <em>N</em> slots whenever a new allocation request comes in, and to continue until we find an empty slot.</p>

  <p class="indent">If the starting slot for each search is truly random between 1 and <em>N</em>, we will not have to invade the overflow area very often. Indeed, if we insert exactly <em>N</em> items starting at random slots, overflow will occur only <span class="middle"><img src="../Images/ch02/e451_01.jpg"></span> times, on the average. The reason is that we can compare this algorithm to hashing with linear probing (Algorithm 6.4L), which has the same behavior except that the search for an empty cell wraps around from <em>N</em> to 1 instead of going into an overflow area. The analysis of Algorithm 6.4L in Theorem 6.4K shows that, when <em>N</em> items have been inserted, the average displacement of each item from its hash address is <span class="middle"><img src="../Images/ch02/e451_02.jpg"></span>; by circular symmetry this average is easily seen to be the same as the average number of times a search goes from slot <em>k</em> to slot <em>k</em> + 1, for each <em>k</em>. Overflows in the distributed-fit method correspond to searches that go from slot <em>N</em> to slot 1, except that our situation is even better because we avoid some congestion by not wrapping around. Therefore fewer than <span class="middle"><img src="../Images/ch02/e451_03.jpg"></span> overflows will occur, on the average. This analysis does not take account of deletions, which preserve the assumptions of Algorithm 6.4L only if we move blocks back when deleting another block that intervened between their starting slots and their allocated slots (see Algorithm 6.4R); again, however, moving them back would only increase the chance of overflow. Our analysis also fails to account for the effect of having more than <em>N</em> blocks present at once; this can happen if we assume only that the arrival time between blocks is about one <em>N</em>th of the residence time. For the case of more than <em>N</em> blocks we need to extend the analysis of Algorithm 6.4L, but Coffman and Leighton proved that the overflow area will almost never need more than <span class="middle"><img src="../Images/ch02/e451_04.jpg"></span> slots; the probability of running off the end is less than <em>O(N<sup>–M</sup>)</em> for all <em>M</em>.</p>

  <p class="indent">In our example, the starting slot for the search during an allocation is not uniform among slots 1, 2, <em>...</em>, <em>N</em>; it is, instead, uniform among slots 1, 65, 129, ..., <em>N</em> − 63, because there are <em>N/</em>256 = 64 slots of each size. But this deviation from the random model considered in the previous paragraph makes overflow even less likely than predicted. All bets are off, of course, if the assumptions about block size distribution and occupancy time are violated.</p>

  <p><strong>F. Overflow.</strong> What do we do when no more room is available? Suppose there is a request for, say, <em>n</em> consecutive words, when all available blocks are too small. The first time this happens, there usually are more than <em>n</em> available locations <a id="page_452"></a>present, but they are not consecutive; compacting memory (that is, moving some of the locations that are in use, so that all available locations are brought together) would mean that we could continue processing. But compacting is slow, and it requires a disciplined use of pointers; moreover, the vast majority of cases in which the first-fit method runs out of room will soon thereafter run completely out of space anyway, no matter how much compacting and re-compacting is done. Therefore it is generally not worthwhile to write a compacting program, except under special circumstances in connection with garbage collection, as in <a href="../Text/ch02c.html#ch02ex_1_5_33">exercise 33</a>. If overflow is expected to occur, some method for removing items from memory and storing them on an external memory device can be used, with provision for bringing the information back again when it is needed. This implies that all programs referring to the dynamic memory area must be severely restricted with regard to the allowable references they make to other blocks, and special computer hardware (for example, interrupt on absence of data, or automatic “paging”) is generally required for efficient operation under these conditions.</p>

  <p class="indent">Some decision procedure is necessary to decide which blocks are the most likely candidates for removal. One idea is to maintain a doubly linked list of the reserved blocks, in which a block is moved up to the front of the list each time it is accessed; then the blocks are effectively sorted in order of their last access, and the block at the rear of the list is the one to remove first. A similar effect can be achieved more simply by putting the reserved blocks into a circular list and including a “recently used” bit in each block; the latter is set to 1 whenever the block is accessed. When it is time to remove a block, a pointer moves along the circular list, resetting all “recently used” bits to 0 until finding a block that has not been used since the last time the pointer reached this part of the circle.</p>

  <p class="indent">J. M. Robson has shown [<em>JACM</em> <strong>18</strong> (1971), 416–423] that dynamic storage allocation strategies that never relocate reserved blocks cannot possibly be guaranteed to use memory efficiently; there will always be pathological circumstances in which the method breaks down. For example, even when blocks are restricted to be of sizes 1 and 2, overflow might occur with the memory only about <span class="middle"><img src="../Images/ch02/2by3.jpg"></span> full, no matter what allocation algorithm is used! Robson’s interesting results are surveyed in <a href="../Text/ch02c.html#ch02ex_1_5_36">exercises 36</a>–<a href="../Text/ch02c.html#ch02ex_1_5_40">40</a>, and in <a href="../Text/ch02c.html#ch02ex_1_5_42">exercises 42</a>–<a href="../Text/ch02c.html#ch02ex_1_5_43">43</a> where he has shown that the best-fit method has a very bad worst case by comparison with first-fit.</p>

  <p><strong>G. For further reading.</strong> A comprehensive survey and critical review of dynamic storage allocation techniques, based on many more years of experience than were available to the author when the material above was written, has been compiled by Paul R. Wilson, Mark S. Johnstone, Michael Neely, and David Boles, <em>Lecture Notes in Computer Science</em> <strong>986</strong> (1995), 1–116.</p>

  <p class="ex-title">Exercises</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_5_1a" id="ch02ex_1_5_1">1</a>.</strong> [<em>20</em>] What simplifications can be made to the reservation and liberation algorithms of this section, if storage requests always appear in a “last-in-first-out” manner, that is, if no reserved block is freed until after all blocks that were reserved subsequently have already been freed?</p>

  <p class="exercises"><a id="page_453"></a><strong><a href="../Text/app01b.html#ch02ex_1_5_2a" id="ch02ex_1_5_2">2</a>.</strong> [<em>HM23</em>] (E. Wolman.) Suppose that we want to choose a fixed node size for variable-length items, and suppose also that when each node has length <em>k</em> and when an item has length <em>l</em>, it takes \lceil{<em>l/</em>(<em>k − b</em>)}\rceil nodes to store this item. (Here <em>b</em> is a constant, signifying that <em>b</em> words of each node contain control information, such as a link to the next node.) If the average length <em>l</em> of an item is <em>L</em>, what choice of <em>k</em> minimizes the average amount of storage space required? (Assume that the average value of <em>(l/</em>(<em>k − b</em>)) mod 1 is equal to 1/2, for any fixed <em>k</em>, as <em>l</em> varies.)</p>

  <p class="exercises"><strong><a id="ch02ex_1_5_3"></a>3.</strong> [<em>40</em>] By computer simulation, compare the best-fit, first-fit, and <em>worst-fit</em> methods of storage allocation; in the latter method, the largest available block is always chosen. Is there any significant difference in the memory usage?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_5_4a" id="ch02ex_1_5_4">4</a>.</strong> [<em>22</em>] Write a <code>MIX</code> program for <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a>, paying special attention to making the inner loop fast. Assume that the <code>SIZE</code> field is (4 : 5), the <code>LINK</code> field is (0 : 2), and <em>Λ</em> &lt; 0.</p>

  <p class="exercises2"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_5a" id="ch02ex_1_5_5">5</a>.</strong> [<em>18</em>] Suppose it is known that <code>N</code> is always 100 or more in <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a>. Would it be a good idea to set <em>c</em> = 100 in the modified step A4′?</p>

  <p class="exercises2"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_6a" id="ch02ex_1_5_6">6</a>.</strong> [<em>23</em>] (<em>Next fit.</em>) After <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> has been used repeatedly, there will be a strong tendency for blocks of small <code>SIZE</code> to remain at the front of the <code>AVAIL</code> list, so that it will often be necessary to search quite far into the list before finding a block of length <code>N</code> or more. For example, notice how the size of the blocks essentially increases in <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a>, for both reserved and free blocks, from the beginning of memory to the end. (The <code>AVAIL</code> list used while <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a> was being prepared was kept sorted by order of location, as required by <a href="../Text/ch02c.html#ch02alg-lev1sec5-B">Algorithm B</a>.) Can you suggest a way to modify <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> so that (a) short blocks won’t tend to accumulate in a particular area, and (b) the <code>AVAIL</code> list may still be kept in order of increasing memory locations, for purposes of algorithms like <a href="../Text/ch02c.html#ch02alg-lev1sec5-B">Algorithm B</a>?</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_5_7a" id="ch02ex_1_5_7">7</a>.</strong> [<em>10</em>] The example (<a href="../Text/ch02c.html#ch02eq-lev1sec5-1">1</a>) shows that first-fit can sometimes be definitely superior to best-fit. Give a similar example that shows a case where best-fit is superior to first-fit.</p>

  <p class="exercises"><strong><a href="../Text/app01b.html#ch02ex_1_5_8a" id="ch02ex_1_5_8">8</a>.</strong> [<em>21</em>] Show how to modify <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> in a simple way to obtain an algorithm for the best-fit method, instead of first-fit.</p>

  <p class="exercises2"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_9a" id="ch02ex_1_5_9">9</a>.</strong> [<em>26</em>] In what ways could a reservation algorithm be designed to use the best-fit method, without searching through the whole <code>AVAIL</code> list? (Try to think of ways that cut down the necessary search as much as possible.)</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_10a" id="ch02ex_1_5_10">10</a>.</strong> [<em>22</em>] Show how to modify <a href="../Text/ch02c.html#ch02alg-lev1sec5-B">Algorithm B</a> so that the block of <code>N</code> consecutive cells beginning at location <code>P0</code> is made available, without assuming that each of these <code>N</code> cells is currently unavailable; assume, in fact, that the area being freed may actually overlap several blocks that are already free.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_11a" id="ch02ex_1_5_11">11</a>.</strong> [<em>M25</em>] Show that the improvement to <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> suggested in the answer to <a href="../Text/ch02c.html#ch02ex_1_5_6">exercise 6</a> can also be used to lead to a slight improvement in <a href="../Text/ch02c.html#ch02alg-lev1sec5-B">Algorithm B</a>, which cuts the average length of search from half the length of the <code>AVAIL</code> list to one-third this length. (Assume that the block being freed will be inserted into a random place within the sorted <code>AVAIL</code> list.)</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_12a" id="ch02ex_1_5_12">12</a>.</strong> [<em>20</em>] Modify <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> so that it follows the boundary-tag conventions of (<a href="../Text/ch02c.html#ch02eq-lev1sec5-7">7</a>)–(<a href="../Text/ch02c.html#ch02eq-lev1sec5-9">9</a>), uses the modified step A4′ described in the text, and also incorporates the improvement of <a href="../Text/ch02c.html#ch02ex_1_5_6">exercise 6</a>.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_13a" id="ch02ex_1_5_13">13</a>.</strong> [<em>21</em>] Write a <code>MIX</code> program for the algorithm of <a href="../Text/ch02c.html#ch02ex_1_5_12">exercise 12</a>.</p>

  <p class="exercises1"><a id="page_454"></a><strong><a href="../Text/app01b.html#ch02ex_1_5_14a" id="ch02ex_1_5_14">14</a>.</strong> [<em>21</em>] What difference would it make to <a href="../Text/ch02c.html#ch02alg-lev1sec5-C">Algorithm C</a> and the algorithm of <a href="../Text/ch02c.html#ch02ex_1_5_12">exercise 12</a>, (a) if the <code>SIZE</code> field were not present in the last word of a free block? or (b) if the <code>SIZE</code> field were not present in the first word of a reserved block?</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_15a" id="ch02ex_1_5_15">15</a>.</strong> [<em>24</em>] Show how to speed up <a href="../Text/ch02c.html#ch02alg-lev1sec5-C">Algorithm C</a> at the expense of a slightly longer program, by not changing any more links than absolutely necessary in each of four cases depending on whether <code>TAG(P0</code> − 1<code>)</code>, <code>TAG(P0</code> + <code>SIZE(P0))</code> are plus or minus.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_16a" id="ch02ex_1_5_16">16</a>.</strong> [<em>24</em>] Write a <code>MIX</code> program for <a href="../Text/ch02c.html#ch02alg-lev1sec5-C">Algorithm C</a>, incorporating the ideas of <a href="../Text/ch02c.html#ch02ex_1_5_15">exercise 15</a>.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_17a" id="ch02ex_1_5_17">17</a>.</strong> [<em>10</em>] What should the contents of <code>LOC(AVAIL)</code> and <code>LOC(AVAIL)</code> + 1 be in (<a href="../Text/ch02c.html#ch02eq-lev1sec5-9">9</a>) when there are no available blocks present?</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_18a" id="ch02ex_1_5_18">18</a>.</strong> [<em>20</em>] <a href="../Text/ch02c.html#ch02fig42">Figures 42</a> and <a href="../Text/ch02c.html#ch02fig43">43</a> were obtained using the same data, and essentially the same algorithms (<a href="../Text/ch02c.html#ch02alg-lev2sec11-A">Algorithms A</a> and <a href="../Text/ch02c.html#ch02alg-lev2sec11-B">B</a>), except that <a href="../Text/ch02c.html#ch02fig43">Fig. 43</a> was prepared by modifying <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a> to choose best-fit instead of first-fit. Why did this cause <a href="../Text/ch02c.html#ch02fig42">Fig. 42</a> to have a large available area in the <em>higher</em> locations of memory, while in <a href="../Text/ch02c.html#ch02fig43">Fig. 43</a> there is a large available area in the <em>lower</em> locations?</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_19a" id="ch02ex_1_5_19">19</a>.</strong> [<em>24</em>] Suppose that blocks of memory have the form of (<a href="../Text/ch02c.html#ch02eq-lev1sec5-7">7</a>), but without the <code>TAG</code> or <code>SIZE</code> fields required in the last word of the block. Suppose further that the following simple algorithm is being used to make a reserved block free again: <code>Q</code> ← <code>AVAIL</code>, <code>LINK(P0)</code> ← <code>Q</code>, <code>LINK(P0</code> +1<code>)</code> ← <code>LOC(AVAIL)</code>, <code>LINK(Q</code> +1<code>)</code> ← <code>P0</code>, <code>AVAIL</code> ← <code>P0</code>, <code>TAG(P0)</code> ← “−”. (This algorithm does nothing about collapsing adjacent areas together.)</p>

  <p class="exercisesp">Design a reservation algorithm, similar to <a href="../Text/ch02c.html#ch02alg-lev1sec5-A">Algorithm A</a>, that does the necessary collapsing of adjacent free blocks while searching the <code>AVAIL</code> list, and at the same time avoids any unnecessary fragmentation of memory as in (<a href="../Text/ch02c.html#ch02eq-lev1sec5-2">2</a>), (<a href="../Text/ch02c.html#ch02eq-lev1sec5-3">3</a>), and (<a href="../Text/ch02c.html#ch02eq-lev1sec5-4">4</a>).</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_20a" id="ch02ex_1_5_20">20</a>.</strong> [<em>00</em>] Why is it desirable to have the <code>AVAIL[</code><em>k</em><code>]</code> lists in the buddy system doubly linked instead of simply having straight linear lists?</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_21a" id="ch02ex_1_5_21">21</a>.</strong> [<em>HM25</em>] Examine the ratio <em>a<sub>n</sub>/b<sub>n</sub></em>, where <em>a<sub>n</sub></em> is the sum of the first <em>n</em> terms of 1 + 2 + 4 + 4 + 8 + 8 + 8 + 8 + 16 + 16 + <em>·</em> · ·, and <em>b<sub>n</sub></em> is the sum of the first <em>n</em> terms of 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + <em>·</em> · ·, as <em>n</em> goes to infinity.</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_22a" id="ch02ex_1_5_22">22</a>.</strong> [<em>21</em>] The text repeatedly states that the buddy system allows only blocks of size 2<em><sup>k</sup></em> to be used, and <a href="../Text/ch02c.html#ch02ex_1_5_21">exercise 21</a> shows this can lead to a substantial increase in the storage required. But if an 11-word block is needed in connection with the buddy system, why couldn’t we find a 16-word block and divide it into an 11-word piece together with two free blocks of sizes 4 and 1?</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_23a" id="ch02ex_1_5_23">23</a>.</strong> [<em>05</em>] What is the binary address of the buddy of the block of size 4 whose binary address is 011011110000? What would it be if the block were of size 16 instead of 4?</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_24a" id="ch02ex_1_5_24">24</a>.</strong> [<em>20</em>] According to the algorithm in the text, the largest block (of size 2<em><sup>m</sup></em>) has no buddy, since it represents all of storage. Would it be correct to define buddy<em><sub>m</sub></em>(0) = 0 (namely, to make this block its own buddy), and then to avoid testing <em>k</em> = <em>m</em> in step S1?</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_25a" id="ch02ex_1_5_25">25</a>.</strong> [<em>22</em>] Criticize the following idea: “Dynamic storage allocation using the buddy system will never reserve a block of size 2<em><sup>m</sup></em> in practical situations (since this would fill the whole memory), and, in general, there is a maximum size 2<em><sup>n</sup></em> for which no blocks of greater size will ever be reserved. Therefore it is a waste of time to start with such large blocks available, and to combine buddies in <a href="../Text/ch02c.html#ch02alg-lev1sec5-S">Algorithm S</a> when the combined block has a size larger than 2<em><sup>n</sup></em>.”</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_26a" id="ch02ex_1_5_26">26</a>.</strong> [<em>21</em>] Explain how the buddy system could be used for dynamic storage allocation in memory locations 0 through <code>M</code>−1 even when <code>M</code> does not have the form 2<em><sup>m</sup></em> as required in the text.</p>

  <p class="exercises1"><a id="page_455"></a><strong><a href="../Text/app01b.html#ch02ex_1_5_27a" id="ch02ex_1_5_27">27</a>.</strong> [<em>24</em>] Write a <code>MIX</code> program for <a href="../Text/ch02c.html#ch02alg-lev1sec5-R">Algorithm R</a>, and determine its running time.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_28a" id="ch02ex_1_5_28">28</a>.</strong> [<em>25</em>] Assume that <code>MIX</code> is a binary computer, with a new operation code <code>XOR</code> defined as follows (using the notation of <a href="../Text/ch01b.html#ch01lev2sec12">Section 1.3.1</a>): “C = 5, F = 5. For each bit position in location M that equals 1, the corresponding bit position in register A is complemented (changed from 0 to 1 or 1 to 0); the sign of rA is unaffected. The execution time is 2<em>u</em>.”</p>

  <p class="indenthangingNP">Write a <code>MIX</code> program for <a href="../Text/ch02c.html#ch02alg-lev1sec5-S">Algorithm S</a>, and determine its running time.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_29a" id="ch02ex_1_5_29">29</a>.</strong> [<em>20</em>] Could the buddy system do without the tag bit in each reserved block?</p>

  <p class="exercises1"><strong><a id="ch02ex_1_5_30"></a>30.</strong> [<em>M48</em>] Analyze the average behavior of <a href="../Text/ch02c.html#ch02alg-lev1sec5-R">Algorithms R</a> and <a href="../Text/ch02c.html#ch02alg-lev1sec5-S">S</a>, given reasonable distributions for the sequence of storage requests.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_31a" id="ch02ex_1_5_31">31</a>.</strong> [<em>M40</em>] Can a storage allocation system analogous to the buddy system be designed using the Fibonacci sequence instead of powers of two? (Thus, we might start with <em>F<sub>m</sub></em> available words, and split an available block of <em>F<sub>k</sub></em> words into two buddies of respective lengths <em>F<sub>k−</sub></em><sub>1</sub> and <em>F<sub>k−</sub></em><sub>2</sub>.)</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_32a" id="ch02ex_1_5_32">32</a>.</strong> [<em>HM46</em>] Determine lim<em><sub>n→∞</sub><em>α</em><sub>n</sub></em>, if it exists, where <em>α</em><sub>n</sub> is the mean value of <em>t<sub>n</sub></em> in a random sequence defined as follows: Given the values of <em>t<sub>k</sub></em> for 0 <em>≤ k &lt; n</em>, let <em>t<sub>n</sub></em> be chosen uniformly from \{1<em>,</em> 2<em>, ..., g<sub>n</sub></em>\}, where</p>

  <div class="image"><img src="../Images/ch02/e455_01.jpg"></div>

  <p class="exercisesp">and <em>f</em>(<em>x</em>) = <em>x</em> if <em>x</em> &gt; 0, <em>f</em>(<em>x</em>) = ∞ if <em>x</em> ≤ 0. [<em>Note:</em> Some limited empirical tests indicate that <em>α</em><sub>n</sub> might be approximately 14, but this is probably not very accurate.]</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_33a" id="ch02ex_1_5_33">33</a>.</strong> [<em>28</em>] (<em>Garbage collection and compacting</em>.) Assume that memory locations 1, 2, ..., <code>AVAIL</code> − 1 are being used as a storage pool for nodes of varying sizes, having the following form: The first word of <code>NODE(P)</code> contains the fields</p>

  <div class="imageL"><img src="../Images/ch02/p0455_01.jpg"></div>

  <p>The node immediately following <code>NODE(P)</code> in memory is <code>NODE(P</code> + <code>SIZE(P))</code>. Assume that the only fields in <code>NODE(P)</code> that are used as links to other nodes are <code>LINK(P</code> + 1<code>)</code>, <code>LINK(P</code> + 2<code>)</code>, <em>...</em>, <code>LINK(P</code> + <code>T(P))</code>, and each of these link fields is either Λ or the address of the first word of another node. Finally, assume that there is one further link variable in the program, called <code>USE</code>, and it points to one of the nodes.</p>

  <p class="indent">Design an algorithm that (i) determines all nodes accessible directly or indirectly from the variable <code>USE</code>, (ii) moves these nodes into memory locations 1 through <code>K</code>−1, for some <code>K</code>, changing all links so that structural relationships are preserved, and (iii) sets <code>AVAIL</code> ← <code>K</code>.</p>

  <p class="indent">For example, consider the following contents of memory, where <code>INFO(L)</code> denotes the contents of location <code>L</code>, excluding <code>LINK(L)</code>:</p>

  <div class="image"><img src="../Images/ch02/455fig01.jpg"></div>

  <p>Your algorithm should transform this into</p>

  <div class="image"><img src="../Images/ch02/455fig02.jpg"></div>

  <p class="exercises1"><a id="page_456"></a><strong><a href="../Text/app01b.html#ch02ex_1_5_34a" id="ch02ex_1_5_34">34</a>.</strong> [<em>29</em>] Write a <code>MIX</code> program for the algorithm of <a href="../Text/ch02c.html#ch02ex_1_5_33">exercise 33</a>, and determine its running time.</p>

  <p class="exercises1"><strong><a id="ch02ex_1_5_35"></a>35.</strong> [<em>22</em>] Contrast the dynamic storage allocation methods of this section with the techniques for variable-size sequential lists discussed at the end of <a href="../Text/ch02.html#ch02lev2sec2">Section 2.2.2</a>.</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_36a" id="ch02ex_1_5_36">36</a>.</strong> [<em>20</em>] A certain lunch counter in Hollywood, California, contains 23 seats in a row. Diners enter the shop in groups of one or two, and a glamorous hostess shows them where to sit. Prove that she will always be able to seat people immediately without splitting up any pairs, if no customer who comes alone is assigned to any of the seats numbered 2, 5, 8, <em>...</em>, 20, provided that there never are more than 16 customers present at a time. (Pairs leave together.)</p>

  <p class="exercises3"><span class="middle"><img src="../Images/ch02/arrow.jpg"></span>&nbsp;&nbsp;&nbsp;<strong><a href="../Text/app01b.html#ch02ex_1_5_37a" id="ch02ex_1_5_37">37</a>.</strong> [<em>26</em>] Continuing <a href="../Text/ch02c.html#ch02ex_1_5_36">exercise 36</a>, prove that the hostess can’t always do such a good job when there are only 22 seats at the counter: No matter what strategy she uses, it will be possible to reach a situation where two friends enter and only 14 people are seated, but no two adjacent seats are vacant.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_38a" id="ch02ex_1_5_38">38</a>.</strong> [<em>M21</em>] (J. M. Robson.) The lunch-counter problem in <a href="../Text/ch02c.html#ch02ex_1_5_36">exercises 36</a> and <a href="../Text/ch02c.html#ch02ex_1_5_37">37</a> can be generalized to establish the worst-case performance of any dynamic storage allocation algorithm that never relocates reserved blocks. Let <em>N</em>(<em>n, m</em>) be the smallest amount of memory such that any series of requests for allocation and liberation can be handled without overflow, provided that all block sizes are <em>≤ m</em> and the total amount of space requested never exceeds <em>n</em>. <a href="../Text/ch02c.html#ch02ex_1_5_36">Exercises 36</a> and <a href="../Text/ch02c.html#ch02ex_1_5_37">37</a> prove that <em>N</em>(16<em>,</em> 2) = 23; determine the exact value of <em>N</em>(<em>n,</em> 2) for all <em>n</em>.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_39a" id="ch02ex_1_5_39">39</a>.</strong> [<em>HM23</em>] (J. M. Robson.) In the notation of <a href="../Text/ch02c.html#ch02ex_1_5_38">exercise 38</a>, show that <em>N</em>(<em>n</em><sub>1</sub>+<em>n</em><sub>2</sub><em>, m</em>) <em>≤ N</em>(<em>n</em><sub>1</sub><em>, m</em>) + <em>N</em>(<em>n</em><sub>2</sub><em>, m</em>) + <em>N</em>(2<em>m</em> − 2<em>, m</em>); hence for fixed <em>m</em>, lim<em><sub>n→∞</sub> N</em>(<em>n, m</em>)<em>/n</em> = <em>N</em>(<em>m</em>) exists.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_40a" id="ch02ex_1_5_40">40</a>.</strong> [<em>HM50</em>] Continuing <a href="../Text/ch02c.html#ch02ex_1_5_39">exercise 39</a>, determine <em>N</em>(3), <em>N</em>(4), and lim<em><sub>m→∞</sub> N</em>(<em>m</em>)<em>/</em> lg <em>m</em> if it exists.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_41a" id="ch02ex_1_5_41">41</a>.</strong> [<em>M27</em>] The purpose of this exercise is to consider the worst-case memory usage of the buddy system. A particularly bad case occurs, for example, if we start with an empty memory and proceed as follows: First reserve <em>n</em> = 2<em><sup>r</sup></em><sup>+1</sup> blocks of length 1, which go into locations 0 through <em>n</em> − 1; then for <em>k</em> = 1, 2, <em>...</em>, <em>r</em>, liberate all blocks whose starting location is not divisible by 2<em><sup>k</sup></em>, and reserve 2<sup>−<em>k</em>−1</sup><em>n</em> blocks of length 2<em><sup>k</sup></em>, which go into locations <span class="middle"><img src="../Images/ch02/e456_01.jpg"></span> through <span class="middle"><img src="../Images/ch02/e456_02.jpg"></span>. This procedure uses <span class="middle"><img src="../Images/ch02/e456_03.jpg"></span> times as much memory as is ever occupied.</p>

  <p class="exercisesp">Prove that the worst case cannot be substantially worse than this: When all requests are for block sizes 1, 2, <em>...</em>, 2<em><sup>r</sup></em>, and if the total space requested at any time never exceeds <em>n</em>, where <em>n</em> is a multiple of 2<em><sup>r</sup></em>, the buddy system will never overflow a memory area of size (<em>r</em> + 1)<em>n</em>.</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_42a" id="ch02ex_1_5_42">42</a>.</strong> [<em>M40</em>] (J. M. Robson, 1975.) Let <em>N</em><sub>BF</sub>(<em>n, m</em>) be the amount of memory needed to guarantee non-overflow when the best-fit method is used for allocation as in <a href="../Text/ch02c.html#ch02ex_1_5_38">exercise 38</a>. Find an attacking strategy to show that <em>N</em><sub>BF</sub>(<em>n, m</em>) <em>≥ mn − O</em>(<em>n</em> + <em>m</em><sup>2</sup>).</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_43a" id="ch02ex_1_5_43">43</a>.</strong> [<em>HM35</em>] Continuing <a href="../Text/ch02c.html#ch02ex_1_5_42">exercise 42</a>, let <em>N</em><sub>FF</sub>(<em>n, m</em>) be the memory needed when the first-fit method is used. Find a defensive strategy to show that <em>N</em><sub>FF</sub>(<em>n, m</em>) <em>≤ H<sub>m</sub>n/</em>ln 2. (Hence the worst case of first-fit is not far from the best possible worst case.)</p>

  <p class="exercises1"><strong><a href="../Text/app01b.html#ch02ex_1_5_44a" id="ch02ex_1_5_44">44</a>.</strong> [<em>M21</em>] Suppose the distribution function <em>F</em> (<em>x</em>) = (probability that a block has size <em>≤ x</em>) is continuous. For example, <em>F</em> (<em>x</em>) is (<em>x − a</em>)<em>/</em>(<em>b − a</em>) for <em>a ≤ x ≤ b</em> if the sizes are uniformly distributed between <em>a</em> and <em>b</em>. Give a formula that expresses the sizes of the first <em>N</em> slots that should be set up when we use the distributed-fit method.</p>

  <div class="heading">
    <h3 id="ch02lev1sec6"><a id="page_457"></a>2.6. History and Bibliography</h3>

    <p>Linear Lists and rectangular arrays of information kept in consecutive memory locations were widely used from the earliest days of stored-program computers, and the earliest treatises on programming gave the basic algorithms for traversing these structures. [For example, see J. von Neumann, <em>Collected Works</em> <strong>5</strong>, 113– 116 (written 1946); M. V. Wilkes, D. J. Wheeler, S. Gill, <em>The Preparation of Programs for an Electronic Digital Computer</em> (Reading, Mass.: Addison– Wesley, 1951), subroutine V-1; and see especially also the work of Konrad Zuse, <em>Berichte der Gesellschaft für Mathematik und Datenverarbeitung</em> <strong>63</strong> (Bonn: 1972), written in 1945. Zuse was the first to develop nontrivial algorithms that worked with lists of dynamically varying lengths.] Before the days of index registers, operations on sequential linear lists were done by performing arithmetic on the machine language instructions themselves, and the need to do such arithmetic was one of the early motivations for having a computer whose programs share memory space with the data they manipulate.</p>
  </div>

  <p class="indent">Techniques that permit variable-length linear lists to share sequential locations, in such a way that they shift back and forth when necessary as described in <a href="../Text/ch02.html#ch02lev2sec2">Section 2.2.2</a>, were apparently a much later invention. J. Dunlap of Digitek Corporation developed such techniques before 1963 in connection with the design of a series of compiler programs; about the same time the idea appeared independently in the design of a COBOL compiler at IBM Corporation, and a collection of related subroutines called CITRUS was subsequently used at various installations. The techniques remained unpublished until after they had been developed independently by Jan Garwick of Norway; see <em>BIT</em> <strong>4</strong> (1964), 137–140.</p>

  <p class="indent">The idea of having linear lists in <em>non</em>sequential locations seems to have originated in connection with the design of computers with rotating drum memories. After executing the instruction in location <em>n</em>, such a computer was usually not ready to get its next instruction from location <em>n</em> + 1, because the drum had already rotated past that point. Depending on the instruction being performed, the most favorable position for the next instruction might be <em>n</em> + 7 or <em>n</em> + 18, say, and the machine could operate up to six or seven times faster if its instructions were located optimally rather than consecutively. [For a discussion of the interesting problems concerning the best placement of instructions, see the author’s article in <em>JACM</em> <strong>8</strong> (1961), 119–150.] Therefore an extra address field was provided in each machine language instruction, to serve as a link to the next command. This idea, called “one-plus-one addressing,” was discussed by John Mauchly in 1946 [<em>Theory and Techniques for the Design of Electronic Computers</em> <strong>4</strong> (U. of Pennsylvania, 1946), Lecture 37]; it contained the notion of linked lists in embryonic form, although the dynamic insertion and deletion operations that we have used so frequently in this chapter were still unknown. Another early appearance of links in programs was in H. P. Luhn’s 1953 memorandum suggesting the use of “chaining” for external searching; see Section 6.4.</p>

  <p class="indent">Linked memory techniques were really born when A. Newell, J. C. Shaw, and H. A. Simon began their investigations of heuristic problem-solving by machine. As an aid to writing programs that searched for proofs in mathematical <a id="page_458"></a>logic, they designed the first List-processing language, IPL-II, in the spring of 1956. (IPL was an acronym for Information Processing Language.) This was a system that made use of pointers and included important concepts like the list of available space, but the concept of stacks was not yet well developed. IPL-III, designed a year later, included “push down” and “pop up” for stacks as important basic operations. [For references to IPL-II see <em>IRE Transactions</em> <strong>IT-2</strong> (September 1956), 61–70; <em>Proc. Western Joint Comp. Conf.</em> <strong>9</strong> (1957), 218–240. Material on IPL-III first appeared in course notes given at the University of Michigan in the summer of 1957.]</p>

  <p class="indent">The work of Newell, Shaw, and Simon inspired many other people to use linked memory, which was often referred to as NSS memory at the time, but mostly for problems dealing with simulation of human thought processes. Gradually, the techniques became recognized as basic computer-programming tools; the first article describing the usefulness of linked memory for “down-to-earth” problems was published by J. W. Carr, III, in <em>CACM</em> <strong>2</strong>, 2 (February 1959), 4–6. Carr pointed out in this article that linked lists can readily be manipulated in ordinary programming languages, without requiring sophisticated subroutines or interpretive systems. See also G. A. Blaauw, “Indexing and control-word techniques,” <em>IBM J. Res. and Dev.</em> <strong>3</strong> (1959), 288–301.</p>

  <p class="indent">At first, one-word nodes were used for linked tables, but about 1959 the usefulness of several consecutive words per node and “multilinked” lists was gradually being discovered by several different groups of people. The first article dealing specifically with this idea was published by D. T. Ross, <em>CACM</em> <strong>4</strong> (1961), 147–150. At that time he used the term “plex” for what has been called a “node” in this chapter, but he subsequently used the word “plex” in a different sense to denote a class of nodes combined with associated algorithms for their traversal.</p>

  <p class="indent">Notations for referring to fields within nodes are generally of two kinds: The name of the field either precedes or follows the pointer designation. Thus, while we have written “<code>INFO(P)</code>” in this chapter, some other authors write, for example, “<code>P.INFO</code>”. At the time this chapter was prepared, the two notations seemed to be equally prominent. The notation adopted here has the great advantage that it translates immediately into FORTRAN, COBOL, or similar languages, if we define <code>INFO</code> and <code>LINK</code> arrays and use <code>P</code> as the index. Furthermore it seems natural to use mathematical functional notation to describe attributes of a node. Note that “<code>INFO(P)</code>” is pronounced “info of <code>P</code>” in conventional mathematical verbalization, just as <em>f</em>(<em>x</em>) is rendered “<em>f</em> of <em>x</em>.” The alternative notation <code>P.INFO</code> has less of a natural flavor, since it tends to put the emphasis on <code>P</code>, although it can be read “<code>P</code>’s info”; the reason <code>INFO(P)</code> seems preferable is apparently the fact that <code>P</code> is variable, but <code>INFO</code> has a fixed significance when the notation is employed. By analogy, we could consider a vector <em>A</em> = (<em>A</em>[1]<em>, A</em>[2]<em>, ..., A</em>[100]) to be a node having 100 fields named 1<em>,</em> 2<em>, ...,</em> 100. Now the second field would be referred to as “<code>2(P)</code>” in our notation, where <code>P</code> points to the vector <em>A</em>; but if we are referring to the <em>j</em> th element of the vector, we find it more natural to write <em>A</em>[<em>j</em>], putting the variable quantity “<em>j</em>” second. Similarly it seems most appropriate to put the variable quantity “<code>P</code>” second in the notation <code>INFO(P)</code>.</p>

  <p class="indent"><a id="page_459"></a>Perhaps the first people to recognize that the concepts “stack” (last-in-first-out) and “queue” (first-in-first-out) are important objects of study were cost accountants interested in reducing income tax assessments; for a discussion of the “LIFO” and “FIFO” methods of pricing inventories, see any intermediate accounting textbook, e.g., C. F. and W. J. Schlatter, <em>Cost Accounting</em> (New York: Wiley, 1957), Chapter 7. In the mid-1940s, A. M. Turing developed a stack mechanism called Reversion Storage for subroutine linkage, local variables, and parameters. His names for “push” and “pop” were “bury” and “disinter/unbury.” (See the references in <a href="../Text/ch01c.html#ch01lev2sec19">Section 1.4.5</a>.) No doubt simple uses of stacks kept in sequential memory locations were common in computer programming from the earliest days, since a stack is such an intuitive concept. The programming of stacks in linked form appeared first in IPL, as stated above; the name “stack” stems from IPL terminology (although “pushdown list” was the more official IPL wording), and it was also independently introduced by E. W. Dijkstra [<em>Numer. Math.</em> <strong>2</strong> (1960), 312–318]. “Deque” is a term coined by E. J. Schweppe in 1966.</p>

  <p class="indent">The origin of circular and doubly linked lists is obscure; presumably these ideas occurred naturally to many people. A strong factor in the popularization of such techniques was the existence of general List-processing systems based on them [principally the Knotted List Structures, <em>CACM</em> <strong>5</strong> (1962), 161–165, and Symmetric List Processor, <em>CACM</em> <strong>6</strong> (1963), 524–544, of J. Weizenbaum]. Ivan Sutherland introduced the use of independent doubly linked lists within larger nodes, in his Sketchpad system (Ph.D. thesis, Mass. Inst. of Technology, 1963).</p>

  <p class="indent">Various methods for addressing and traversing multidimensional arrays of information were developed independently by clever programmers since the earliest days of computers, and thus another part of the unpublished computer folklore was born. This subject was first surveyed in print by H. Hellerman, <em>CACM</em> <strong>5</strong> (1962), 205–207. See also J. C. Gower, <em>Comp. J.</em> <strong>4</strong> (1962), 280–286.</p>

  <p class="indent">Tree structures represented explicitly in computer memory were originally used for applications to algebraic formula manipulation. The machine language for several early computers used a three-address code to represent the computation of arithmetic expressions; the latter is equivalent to the <code>INFO</code>, <code>LLINK</code>, and <code>RLINK</code> of a binary tree representation. In 1952, H. G. Kahrimanian developed algorithms for differentiating algebraic formulas represented in an extended three-address code; see <em>Symposium on Automatic Programming</em> (Washington, D.C.: Office of Naval Research, May 1954), 6–14.</p>

  <p class="indent">Since then, tree structures in various guises have been studied independently by many people in connection with numerous computer applications, but the basic techniques for tree manipulation (not general List manipulation) have seldom appeared in print except in detailed description of particular algorithms. The first general survey was made in connection with a more general study of all data structures by K. E. Iverson and L. R. Johnson [IBM Corp. research reports RC-390, RC-603, 1961; see Iverson, <em>A Programming Language</em> (New York: Wiley, 1962), Chapter 3]. See also G. Salton, <em>CACM</em> <strong>5</strong> (1962), 103–114.</p>

  <p class="indent">The concept of <em>threaded</em> trees is due to A. J. Perlis and C. Thornton, <em>CACM</em> <strong>3</strong> (1960), 195–204. Their paper also introduced the important idea of traversing <a id="page_460"></a>trees in various orders, and gave numerous examples of algebraic manipulation algorithms. Unfortunately, this important paper was prepared hastily and it contains many misprints. The threaded lists of Perlis and Thornton were only “right-threaded trees” in our terminology; binary trees that are threaded in <em>both</em> directions were independently discovered by A. W. Holt, <em>A Mathematical and Applied Investigation of Tree Structures</em> (Thesis, U. of Pennsylvania, 1963). Postorder and preorder for the nodes of trees were called “normal along order” and “dual along order” by Z. Pawlak [<em>Colloquium on the Foundation of Mathematics</em>, Tihany, 1962 (Budapest: Akadémiai Kiadó, 1965), 227–238]. Preorder was called “subtree order” by Iverson and Johnson in the references cited above. Graphical ways to represent the connection between tree structures and corresponding linear notations were described by A. G. Oettinger, <em>Proc. Harvard Symp. on Digital Computers and their Applications</em> (April 1961), 203–224. The representation of trees in preorder by degrees, with associated algorithms relating this representation to Dewey decimal notation and other properties of trees, was presented by S. Gorn, <em>Proc. Symp. Math. Theory of Automata</em> (Brooklyn: Poly. Inst., 1962), 223–240.</p>

  <p class="indent">The history of tree structures as mathematical entities, together with a bibliography of the subject, is reviewed in <a href="../Text/ch02b.html#ch02lev3sec6">Section 2.3.4.6</a>.</p>

  <p class="indent">At the time this section was first written in 1966, the most widespread knowledge about information structures was due to programmers’ exposure to List processing systems, which played a very important part in this history. The first widely used system was IPL-V (a descendant of IPL-III, developed late in 1959); IPL-V was an interpretive system in which a programmer learned a machine-like language for List operations. At about the same time, FLPL (a set of FORTRAN subroutines for List manipulation, also inspired by IPL but using subroutine calls instead of interpretive language) was developed by H. Gelernter and others. A third system, LISP, was designed by J. McCarthy, also in 1959. LISP was quite different from its predecessors: Its programs were (and still are) expressed in mathematical functional notation combined with “conditional expressions,” then converted into a List representation. Many List processing systems came into existence during the 1960s; the most prominent among these from a historical standpoint was J. Weizenbaum’s SLIP, a set of subroutines that implemented doubly linked Lists in FORTRAN.</p>

  <p class="indent">An article by Bobrow and Raphael, <em>CACM</em> <strong>7</strong> (1964), 231–240, may be read as a brief introduction to IPL-V, LISP, and SLIP; it gives a comparison of these systems. An excellent early introduction to LISP was published by P. M. Woodward and D. P. Jenkins, <em>Comp. J.</em> <strong>4</strong> (1961), 47–53. See also the authors’ discussions of their own systems, which are articles of considerable historical importance: “An introduction to IPL-V” by A. Newell and F. M. Tonge, <em>CACM</em> <strong>3</strong> (1960), 205–211; “A FORTRAN-compiled List Processing Language” by H. Gelernter, J. R. Hansen, and C. L. Gerberich, <em>JACM</em> <strong>7</strong> (1960), 87– 101; “Recursive functions of symbolic expressions and their computation by machine, I” by John McCarthy, <em>CACM</em> <strong>3</strong> (1960), 184–195; “Symmetric List Processor” by J. Weizenbaum, <em>CACM</em> <strong>6</strong> (1963), 524–544. Weizenbaum’s article <a id="page_461"></a>included a complete description of all of the algorithms used in SLIP. Of all these early systems, only LISP had the necessary ingredients to survive the ensuing decades of further progress. McCarthy has described LISP’s early history in <em>History of Programming Languages</em> (Academic Press, 1981), 173–197.</p>

  <p class="indent">Several <em>string manipulation</em> systems also appeared during the 1960s; they were primarily concerned with operations on variable-length strings of alphabetic information — looking for occurrences of certain substrings and replacing them by others, etc. The most important of these from a historical perspective were COMIT [V. H. Yngve, <em>CACM</em> <strong>6</strong> (1963), 83–84] and SNOBOL [D. J. Farber, R. E. Griswold, and I. P. Polonsky, <em>JACM</em> <strong>11</strong> (1964), 21–30]. String manipulation systems were used widely, and they were composed primarily of algorithms like the ones we have seen in this chapter, but they played a comparatively small role in the history of the techniques of information structure representation; users of such systems were isolated from the details of the actual internal processes carried on by the computer. For a survey of early string manipulation techniques, see S. E. Madnick, <em>CACM</em> <strong>10</strong> (1967), 420–424.</p>

  <p class="indent">The IPL-V and FLPL systems for List-processing did not use either a garbage collection or a reference count technique for the problem of shared Lists; instead, each List was “owned” by one List and “borrowed” by all other Lists that referred to it, and a List was erased when its “owner” allowed it to disappear. Hence, the programmer was enjoined to make sure that no List was still borrowing any Lists that were being erased. The reference counter technique for Lists was introduced by G. E. Collins, <em>CACM</em> <strong>3</strong> (1960), 655–657, and explained further in <em>CACM</em> <strong>9</strong> (1966), 578–588. Garbage collection was first described in McCarthy’s article of 1960; see also Weizenbaum’s remarks in <em>CACM</em> <strong>7</strong> (1964), 38, and an article by Cohen and Trilling, <em>BIT</em> <strong>7</strong> (1967), 22–30.</p>

  <p class="indent">An increasing realization of the importance of link manipulations led naturally to their inclusion in algebraic programming languages designed after 1965. The new languages allowed programmers to choose suitable forms of data representation without resorting to assembly language or paying the overhead of completely general List structures. Some of the fundamental steps in this development were the work of N. Wirth and H. Weber [<em>CACM</em> <strong>9</strong> (1966), 13–23, 25, 89–99]; H. W. Lawson [<em>CACM</em> <strong>10</strong> (1967), 358–367]; C. A. R. Hoare [<em>Symbol Manipulation Languages and Techniques</em>, ed. by D. G. Bobrow (Amsterdam: North-Holland, 1968), 262–284]; O.-J. Dahl and K. Nygaard [<em>CACM</em> <strong>9</strong> (1966), 671–678]; A. van Wijngaarden, B. J. Mailloux, J. E. L. Peck, and C. H. A. Koster [<em>Numerische Math.</em> <strong>14</strong> (1969), 79–218]; Dennis M. Ritchie [<em>History of Programming Languages — II</em> (ACM Press, 1996), 671–698].</p>

  <p class="indent">Dynamic storage allocation algorithms were in use several years before they were ever described in print. A very readable discussion was prepared by W. T. Comfort in 1961 and published in <em>CACM</em> <strong>7</strong> (1964), 357–362. The boundary-tag method, introduced in <a href="../Text/ch02c.html#ch02lev1sec5">Section 2.5</a>, was designed by the author in 1962 for use in an operating system for the Burroughs B5000 computer. The buddy system was first used by H. Markowitz in connection with the SIMSCRIPT programming system in 1963, and it was independently discovered and published <a id="page_462"></a>by K. Knowlton, <em>CACM</em> <strong>8</strong> (1965), 623–625; see also <em>CACM</em> <strong>9</strong> (1966), 616–625. For additional early discussions of dynamic storage allocation, see the articles by Iliffe and Jodeit, <em>Comp. J.</em> <strong>5</strong> (1962), 200–209; Bailey, Barnett, and Burleson, <em>CACM</em> <strong>7</strong> (1964), 339–346; A. T. Berztiss, <em>CACM</em> <strong>8</strong> (1965), 512–513; and D. T. Ross, <em>CACM</em> <strong>10</strong> (1967), 481–492.</p>

  <p class="indent">A general discussion of information structures and their relation to programming was prepared by Mary d’Imperio, “Data Structures and their Representation in Storage,” <em>Annual Review in Automatic Programming</em> <strong>5</strong> (Oxford: Pergamon Press, 1969). Her paper is a valuable guide to the history of the topic, since it includes a detailed analysis of the structures used in connection with twelve List processing and string manipulation systems. See also the proceedings of two symposia, <em>CACM</em> <strong>3</strong> (1960), 183–234 and <em>CACM</em> <strong>9</strong> (1966), 567–643, for further historical details. (Several of the individual papers from those proceedings have already been cited above.)</p>

  <p class="indent">An excellent annotated bibliography of early work on symbol manipulation and algebraic formula manipulation, having numerous connections with the material of this chapter, was compiled by Jean E. Sammet; see <em>Computing Reviews</em> <strong>7</strong> (July–August 1966), B1–B31.</p>

  <p class="indent">In this chapter we have looked at particular types of information structures in great detail, and (lest we fail to see the forest for the trees) it is perhaps wise to take stock of what we have learned and to summarize briefly the general subject of information structures from a broader perspective. Starting with the basic idea of a <em>node</em> as an element of data, we have seen many examples that illustrate convenient ways to represent structural relationships either implicitly (based on the relative order in which nodes are stored in computer memory) or explicitly (by means of links in the nodes, which point to other nodes). The amount of structural information that ought to be represented within the tables of a computer program depends on the operations that are to be performed on the nodes.</p>

  <p class="indent">For pedagogic reasons, we have largely concentrated on the connections between information structures and their machine representations, instead of discussing those issues separately. However, to gain a deeper understanding it is helpful to consider the subject from a more abstract point of view, distilling off several layers of ideas that can be studied by themselves. Several noteworthy approaches of this kind have been developed, and the following thought-provoking papers are especially recommended from the early literature: G. Mealy, “Another look at data,” <em>Proc. AFIPS Fall Joint Computer Conf.</em> <strong>31</strong> (1967), 525–534; J. Earley, “Toward an understanding of data structures,” <em>CACM</em> <strong>14</strong> (1971), 617– 627; C. A. R. Hoare, “Notes on data structuring,” in <em>Structured Programming</em> by O.-J. Dahl, E. W. Dijkstra, and C. A. R. Hoare (Academic Press, 1972), 83– 174; Robert W. Engles, “A tutorial on data-base organization,” <em>Annual Review in Automatic Programming</em> <strong>7</strong> (1972), 3–63.</p>

  <p class="indent">The discussion in this chapter does not cover the entire subject of information structures in full generality; at least three important aspects of the subject have not been treated here:</p>

  <p class="indent"><a id="page_463"></a>a) We often want to search through a table to find a node or set of nodes possessing a certain value, and the need for such an operation often has a profound effect on the structure of the table. This situation is explored in detail in Chapter 6.</p>

  <p class="indent">b) We have primarily been concerned with the internal representation of structure within a computer; but that is obviously only part of the story, since structure must also be represented in the external input and output data. In simple cases, external structure can be treated by essentially the same techniques that we have been considering; but the processes of converting between strings of characters and more complex structures are also very important. Those processes are analyzed in Chapters 9 and 10.</p>

  <p class="indent">c) We have primarily discussed representations of structures within a high-speed random-access memory. When slower memory devices such as disks or tapes are being used, we find that all of the structural problems are intensified; it becomes much more crucial to have efficient algorithms and efficient schemes for data representation. Nodes that link to each other in such cases ought to go into nearby areas of the memory. Usually the problems are highly dependent on the characteristics of individual machines, so it is difficult to discuss them in general. The simpler examples treated in this chapter should help to prepare the reader for solving the more difficult problems that arise in connection with less ideal memory devices; Chapters 5 and 6 discuss some of these problems in detail.</p>

  <p class="indent">What are the main implications of the subjects treated in this chapter? Perhaps the most important conclusion we can reach is that the ideas we have encountered are not limited to computer programming alone; they apply more generally to everyday life. A collection of nodes containing fields, some of which point to other nodes, appears to be a very good abstract model for structural relationships of all kinds. This model shows how we can build up complicated structures from simple ones, and we have seen that corresponding algorithms for manipulating the structure can be designed in a natural manner.</p>

  <p class="indent">Therefore it seems appropriate to develop much more theory about linked sets of nodes than we know at this time. Perhaps the most obvious way to start such a theory is to define a new kind of abstract machine or “automaton” that deals with linked structures. For example, such a device might be defined informally as follows: There are numbers <em>k</em>, <em>l</em>, <em>r</em>, and <em>s</em>, such that the automaton processes nodes containing <em>k</em> link fields and <em>r</em> information fields; it has <em>l</em> link registers and <em>s</em> information registers, which enable it to control the processes it is performing. The information fields and registers may contain any symbols from some given set of information symbols; each of the link fields and link registers either contains <em>Λ</em> or points to a node. The machine can (i) create new nodes (putting a link to the node into a register), (ii) compare information symbols or link values for equality, and (iii) transfer information symbols or link values between registers and nodes. Only nodes pointed to by link registers are immediately accessible. Suitable restrictions on the machine’s behavior will make it equivalent to several other species of automata.</p>

  <p class="indent"><a id="page_464"></a>A related model of computation was proposed by A. N. Kolmogorov as early as 1952. His machine essentially operates on graphs <em>G</em>, having a specially designated starting vertex <em>v</em><sub>0</sub>. The action at each step depends only on the subgraph <em>G</em>′ consisting of all vertices at distance <em>≤ n</em> from <em>v</em><sub>0</sub> in <em>G</em>, replacing <em>G</em>′ in <em>G</em> by another graph <em>G<sup>′′</sup></em> = <em>f</em>(<em>G</em>′), where <em>G<sup>′′</sup></em> includes <em>v</em><sub>0</sub> and the vertices at distance exactly <em>n</em> from <em>v</em><sub>0</sub>, and possibly other vertices (which are newly created); the remainder of graph <em>G</em> is left unaltered. Here <em>n</em> is a fixed number specified in advance for any particular algorithm, but it can be arbitrarily large. A symbol from a finite alphabet is attached to each vertex, and restrictions are made so that no two vertices with the same symbol can be adjacent to a common vertex. (See A. N. Kolmogorov, <em>Uspekhi Mat. Nauk</em> <strong>8</strong>, 4 (1953), 175– 176; Kolmogorov and Uspensky, <em>Uspekhi Mat. Nauk</em> <strong>13</strong>, 4 (1958), 3–28; <em>Amer. Math. Soc. Translations</em>, series 2, <strong>29</strong> (1963), 217–245.)</p>

  <p class="indent">Linking automata can easily simulate graph machines, taking at most a bounded number of steps per graph step. Conversely, however, it is unlikely that graph machines can simulate arbitrary linking automata without unboundedly increasing the running time, unless the definition is changed from undirected to directed graphs, in view of the restriction to vertices of bounded degree. The linking model is, of course, quite close to the operations available to programmers on real machines, while the graph model is not.</p>

  <p class="indent">Some of the most interesting problems to solve for such devices would be to determine how fast they can solve certain problems, or how many nodes they need to solve certain problems (for example, to translate certain formal languages). At the time this chapter was first written, several interesting results of this kind had been obtained (notably by J. Hartmanis and R. E. Stearns) but only for special classes of Turing machines having multiple tapes and read/write heads. The Turing machine model is comparatively unrealistic, so these results tended to have little to do with practical problems.</p>

  <p class="indent">We must admit that, as the number <em>n</em> of nodes created by a linking automaton approaches infinity, we don’t know how to build such a device physically, since we want the machine operations to take the same amount of time regardless of the size of <em>n</em>; if linking is represented by using addresses as in a computer memory, it is necessary to put a bound on the number of nodes, since the link fields have a fixed size. A multitape Turing machine is therefore a more realistic model when <em>n</em> approaches infinity. Yet it seems reasonable to believe that a linking automaton as described above leads to a more appropriate theory of the complexity of algorithms than Turing machines do, even when asymptotic formulas for large <em>n</em> are considered, because the theory is more likely to be relevant for practical values of <em>n</em>. Furthermore when <em>n</em> gets bigger than 10<sup>30</sup> or so, not even a one-tape Turing machine is realistic: It could never be built. Relevance is more important than realism.</p>

  <p class="indent">Many years have passed since the author wrote most of the comments above, and everybody can be glad that substantial progress has indeed been made on the theory of linking automata (now called <em>pointer machines</em>). But of course much still remains to be done.</p>

  <p class="blockquote"><a id="page_465"></a><span class="roman_italic">General rules for programming have been discovered.<br>
  Most of them have been used in the<br>
  Kansas City freight yards for a long time.</span></p>

  <p class="attribution">— DERRICK LEHMER (1949)</p>

  <p class="blockquote"><span class="roman_italic">I must explain, to begin with,<br>
  that all the Trees, in this system, grow</span> head-downwards:<br>
  <span class="roman_italic">the Root is at the</span> top, <span class="roman_italic">and the Branches are</span> below.<br>
  <span class="roman_italic">If it be objected that the name “Tree” is a misnomer, my answer<br>
  is that I am only following the example of all writers on</span> Genealogy.<br>
  <span class="roman_italic">A</span> Genealogical <span class="roman_italic">tree</span> always <span class="roman_italic">grows</span> downwards:<br>
  <span class="roman_italic">then why many not a</span> Logical <span class="roman_italic">“Tree” do likewise?</span></p>

  <p class="attribution">— LEWIS CARROLL, in <span class="roman_italic">Symbolic Logic</span> (1896)</p>

  <p class="blockquote"><span class="roman_italic">You will, I am sure, agree with me ... that if page<br>
  534 finds us only in the second chapter, the length of<br>
  the first one must have been really intolerable.</span></p>

  <p class="attribution">— SHERLOCK HOLMES, in <span class="roman_italic">The Valley of Fear</span> (1888)</p>
</body>
</html>